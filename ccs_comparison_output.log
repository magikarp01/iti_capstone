Loaded dataset: imdb
Dataset({
    features: ['text', 'label'],
    num_rows: 25000
})
Loaded dataset: amazon_polarity
Dataset({
    features: ['label', 'title', 'content', 'text'],
    num_rows: 3600000
})
Loaded dataset: ag_news
Dataset({
    features: ['text', 'label'],
    num_rows: 120000
})
Loaded dataset: dbpedia_14
Dataset({
    features: ['label', 'title', 'content', 'text'],
    num_rows: 560000
})
Loaded dataset: super_glue/copa
Dataset({
    features: ['text', 'text1', 'text2', 'question', 'idx', 'label', '__index_level_0__'],
    num_rows: 500
})
Loaded dataset: super_glue/rte
Dataset({
    features: ['text', 'text1', 'idx', 'label'],
    num_rows: 2490
})
Loaded dataset: boolq
Dataset({
    features: ['text1', 'label', 'text'],
    num_rows: 9427
})
Loaded dataset: glue/qnli
Dataset({
    features: ['text', 'text1', 'label', 'idx'],
    num_rows: 104743
})
Loaded dataset: piqa
Dataset({
    features: ['text', 'text1', 'text2', 'label'],
    num_rows: 16113
})
Loaded dataset: chenxwh/gen-storycloze
Dataset({
    features: ['story_id', 'input_sentence_1', 'input_sentence_2', 'input_sentence_3', 'input_sentence_4', 'text', 'text1', 'text2', 'answer_right_ending', 'text_right_ending', 'text_wrong_ending', 'label'],
    num_rows: 1785
})
[2023-07-06 18:02:26,768] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Models loaded successfully!
 **** Loaded model:  deberta
 *** Training on  imdb  and testing on  imdb
loaded data
Memory used, total: 2.92 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [23654, 23654, 15795, 15795, 860, 860, 5390, 5390, 21575, 21575, 11964, 11964, 11284, 11284, 22118, 22118, 6265, 6265, 16850, 16850, 4426, 4426, 21962, 21962, 14423, 11363, 11363, 16023, 16023, 8322, 8322, 1685, 1685, 769, 769, 23333, 23333, 2433, 2433, 5311, 5311, 5051, 5051, 6420, 6420, 17568, 17568, 20939, 20939, 19769, 19769, 6396, 6396, 8666, 8666, 18942, 18942, 24233, 24233, 18431, 18431, 2747, 2747, 189, 189, 19118, 19118, 3005, 3005, 21042, 21042, 1899, 1899, 24118, 24118, 1267, 17912, 17912, 11394, 11394, 3556, 3556, 3890, 3890, 8838, 14502, 14502, 21777, 21777, 10627, 10627, 8792, 10555, 10555, 10253, 10253, 8433, 8433, 10233, 10233, 11016, 11016, 23897, 23897, 2612, 2612, 23425, 23425, 22619, 22619, 21870, 21870, 23483, 23483, 15787, 15787, 17159, 17159, 12206, 12206, 8226, 8226, 14541, 14541, 3152, 3152, 1585, 1585, 3943, 3943, 23939, 23939, 19457, 19457, 1021, 1021, 11653, 11653, 10805, 10805, 13417, 13417, 20227, 20227, 7989, 7989, 9692, 9692, 12990, 12990, 6873, 6873, 5675, 5675, 161, 161, 4297, 4297, 995, 995, 11534, 11534, 7629, 7629, 1016, 1016, 24253, 24253, 22823, 24276, 24276, 23247, 23247, 24300, 24300, 8529, 8529, 17262, 17262, 9268, 9268, 21271, 21271, 12185, 12185, 21243, 21243, 6331, 6331, 8571, 8571, 7208, 7208, 5276, 18446, 18446, 16448, 16448, 16216, 16216, 8006, 2568, 2568, 21847, 21847, 2027, 2027, 2695, 2695, 15422, 15422, 5258, 5258, 22002, 22002, 6736, 6736, 391, 391, 13986, 13986, 12666, 12666, 5892, 5892, 3561, 3561, 6184, 6184, 19483, 19483, 22662, 8392, 13067, 13067, 15265, 15265, 19488, 19488, 23599, 23599, 2454, 2454, 11837, 11837, 14039, 14039, 19115, 19115, 10965, 10965, 24538, 24538, 9762, 9762, 5056, 5056, 14948, 8110, 8110, 13773, 20224, 20224, 17412, 17412, 23769, 502, 502, 6910, 6910, 12685, 12685, 23322, 23322, 20872, 206, 206, 21518, 21518, 22361, 22361, 24105, 24105, 23419, 23419, 17868, 17868, 24242, 24242, 15934, 15934, 17247, 17247, 19174, 23792, 23792, 8755, 8755, 21500, 12383, 12383, 22403, 22403, 18141, 18141, 14820, 14820, 7574, 6374, 6374, 23276, 23276, 1678, 1678, 19626, 21020, 1059, 1059, 23052, 23052, 16198, 16198, 9914, 9914, 19541, 19541, 22299, 10817, 10817, 10921, 9789, 9789, 16312, 16312, 11252, 11252, 2693, 2693, 13931, 3627, 3627, 16157, 10173, 10173, 21834, 21834, 18047, 18047, 10230, 10230, 15707, 15707, 21976, 21976, 11494, 11494, 23776, 1306, 6776, 22248, 22248, 9474, 9474, 7526, 7526, 21959, 5530, 5530, 20797, 20797, 3748, 13545, 13545, 663, 663, 1998, 1998, 7994, 17879, 17879, 3304, 3304, 20147, 20147, 21616, 18237, 18237, 13808, 6585, 6585, 17675, 17675, 19965, 11649, 11649, 23938, 23938, 23664, 1636, 1636, 20080, 20080, 17082, 17082, 4737, 4737, 14555, 14555, 13877, 854, 854, 24548, 24548, 5855, 5855, 7392, 22912, 22912, 13949, 13949, 21633, 21556, 21556, 18091, 18091, 5791, 5791, 21919, 21919, 4931, 4931, 19894, 19894, 202, 202, 11447, 11447, 20602, 20602, 12688, 12688, 4389, 4389, 2327, 2327, 8004, 8004, 19315, 7777, 7777, 197, 23509, 1930, 1930, 11774, 11774, 15087, 15087, 22671, 22671, 9339, 9339, 20666, 11589, 11589, 18895, 18895, 15708, 15708, 17043, 17043, 2811, 2811, 23482, 23482, 14243, 14243, 6546, 6546, 1986, 1986, 8338, 8338, 11411, 11411, 2911, 2911, 1734, 1734, 18227, 8680, 8680, 19360, 18343, 18343, 5759, 5759, 23078, 23078, 2385, 2385, 11111, 11111, 4736, 4736, 1802, 1802, 8155, 8155, 8120, 8120, 6616, 6616, 14257, 14257, 14486, 21918, 21918, 20445, 20445, 16646, 16646, 14075, 14075, 9208, 16371, 16371, 11835, 11835, 13168, 13168, 2049, 2049, 5423, 5423, 14589, 14589, 20932, 20932, 19492, 19492, 7158, 7158, 10248, 10248, 7400, 7400, 19554, 19554, 9874, 9874, 15151, 15151, 18639, 18639, 1154, 1154, 4499, 4499, 6295, 6295, 22581, 22581, 12183, 12183, 12874, 12874, 18032, 5539, 9637, 20583, 24829, 24829, 15586, 15586, 2557, 2557, 5592, 5592, 16482, 16482, 2200, 14172, 2961, 2961, 14207, 14207, 21357, 21357, 20817, 20817, 11969, 11969, 2869, 2869, 17340, 17340, 13992, 13992, 24736, 24736, 5699, 5699, 23328, 23328, 20877, 20877, 21295, 21295, 3987, 3987, 22399, 22399, 13446, 13446, 1218, 1218, 20880, 20880, 4735, 4735, 11296, 11296, 4555, 4555, 9146, 9146, 8050, 12757, 12757, 19830, 19830, 17429, 6893, 6893, 18077, 18077, 14373, 14565, 14565, 3436, 8754, 10677, 10677, 5895, 5895, 19738, 19738, 16609, 16609, 15636, 15636, 21277, 21277, 7022, 7022, 9151, 5600, 5600, 7996, 7996, 9007, 9007, 12946, 12946, 24067, 24067, 4642, 4642, 11312, 11312, 7679, 8208, 8208, 23723, 23723, 18589, 18589, 10716, 10716, 17453, 17453, 3444, 3444, 10757, 10757, 14434, 14434, 1060, 1060, 18711, 3420, 3420, 301, 301, 12468, 12468, 16990, 16990, 699, 699, 21472, 21472, 190, 190, 10492, 10492, 17364, 17364, 2975, 2975, 6102, 6102, 19711, 19711, 19778, 19778, 24703, 1816, 1816, 22238, 22238, 23093, 569, 569, 5442, 5442, 1895, 1895, 19117, 19117, 3863, 12913, 12913, 7455, 4014, 11093, 18070, 18070, 3009, 24190, 24190, 16538, 16538, 10729, 1409, 12249, 784, 8096, 7560, 12533, 12533, 7343, 7206, 21980, 21980, 5801, 19190, 16921, 5986, 18225, 18225, 10647, 8716, 23355, 23355, 22009, 19334, 19334, 24376, 12323, 4780, 2368, 12039, 6655, 8173, 4495, 10893, 22386, 22386, 22998, 22998, 13403, 13403, 13121, 13121, 22303, 22303]
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9628571428571429
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9942857142857143
CCS accuracy on own: 0.9828571428571429
 *** Training on  imdb  and testing on  amazon_polarity
loaded data
Memory used, total: 3.14 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9971428571428571
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9914285714285714
CCS accuracy on own: 0.9828571428571429
 *** Training on  imdb  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.49333333333333335
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.4771428571428571
CCS accuracy on own: 0.040000000000000036
 *** Training on  imdb  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.3564835164835165
Logistic regression accuracy on own: 0.9885714285714285
CCS accuracy on transfer: 0.4674725274725275
CCS accuracy on own: 0.9828571428571429
 *** Training on  imdb  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.4257142857142857
Logistic regression accuracy on own: 0.98
CCS accuracy on transfer: 0.6914285714285715
CCS accuracy on own: 0.9971428571428571
 *** Training on  imdb  and testing on  rte
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.44571428571428573
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.58
CCS accuracy on own: 0.008571428571428572
 *** Training on  imdb  and testing on  boolq
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.21428571428571427
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9771428571428571
CCS accuracy on own: 0.9828571428571429
 *** Training on  imdb  and testing on  qnli
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9942857142857143
Logistic regression accuracy on own: 0.98
CCS accuracy on transfer: 0.9971428571428571
CCS accuracy on own: 0.9771428571428571
 *** Training on  imdb  and testing on  piqa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.15142857142857144
Logistic regression accuracy on own: 0.9857142857142858
CCS accuracy on transfer: 0.9542857142857143
CCS accuracy on own: 0.9885714285714285
 *** Training on  imdb  and testing on  story-cloze
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.66
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.0
CCS accuracy on own: 0.9942857142857143
 *** Training on  amazon_polarity  and testing on  imdb
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
Loaded dataset: imdb
Dataset({
    features: ['text', 'label'],
    num_rows: 25000
})
Loaded dataset: amazon_polarity
Dataset({
    features: ['label', 'title', 'content', 'text'],
    num_rows: 3600000
})
Loaded dataset: ag_news
Dataset({
    features: ['text', 'label'],
    num_rows: 120000
})
Loaded dataset: dbpedia_14
Dataset({
    features: ['label', 'title', 'content', 'text'],
    num_rows: 560000
})
Loaded dataset: super_glue/copa
Dataset({
    features: ['text', 'text1', 'text2', 'question', 'idx', 'label', '__index_level_0__'],
    num_rows: 500
})
Loaded dataset: super_glue/rte
Dataset({
    features: ['text', 'text1', 'idx', 'label'],
    num_rows: 2490
})
Loaded dataset: boolq
Dataset({
    features: ['text1', 'label', 'text'],
    num_rows: 9427
})
Loaded dataset: glue/qnli
Dataset({
    features: ['text', 'text1', 'label', 'idx'],
    num_rows: 104743
})
Loaded dataset: piqa
Dataset({
    features: ['text', 'text1', 'text2', 'label'],
    num_rows: 16113
})
Loaded dataset: chenxwh/gen-storycloze
Dataset({
    features: ['story_id', 'input_sentence_1', 'input_sentence_2', 'input_sentence_3', 'input_sentence_4', 'text', 'text1', 'text2', 'answer_right_ending', 'text_right_ending', 'text_wrong_ending', 'label'],
    num_rows: 1785
})
[2023-07-06 19:06:59,658] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Models loaded successfully!
 **** Loaded model:  deberta
 *** Training on  imdb  and testing on  imdb
loaded data
Memory used, total: 2.92 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [23654, 23654, 15795, 15795, 860, 860, 5390, 5390, 21575, 21575, 11964, 11964, 11284, 11284, 22118, 22118, 6265, 6265, 16850, 16850, 4426, 4426, 21962, 21962, 14423, 11363, 11363, 16023, 16023, 8322, 8322, 1685, 1685, 769, 769, 23333, 23333, 2433, 2433, 5311, 5311, 5051, 5051, 6420, 6420, 17568, 17568, 20939, 20939, 19769, 19769, 6396, 6396, 8666, 8666, 18942, 18942, 24233, 24233, 18431, 18431, 2747, 2747, 189, 189, 19118, 19118, 3005, 3005, 21042, 21042, 1899, 1899, 24118, 24118, 1267, 17912, 17912, 11394, 11394, 3556, 3556, 3890, 3890, 8838, 14502, 14502, 21777, 21777, 10627, 10627, 8792, 10555, 10555, 10253, 10253, 8433, 8433, 10233, 10233, 11016, 11016, 23897, 23897, 2612, 2612, 23425, 23425, 22619, 22619, 21870, 21870, 23483, 23483, 15787, 15787, 17159, 17159, 12206, 12206, 8226, 8226, 14541, 14541, 3152, 3152, 1585, 1585, 3943, 3943, 23939, 23939, 19457, 19457, 1021, 1021, 11653, 11653, 10805, 10805, 13417, 13417, 20227, 20227, 7989, 7989, 9692, 9692, 12990, 12990, 6873, 6873, 5675, 5675, 161, 161, 4297, 4297, 995, 995, 11534, 11534, 7629, 7629, 1016, 1016, 24253, 24253, 22823, 24276, 24276, 23247, 23247, 24300, 24300, 8529, 8529, 17262, 17262, 9268, 9268, 21271, 21271, 12185, 12185, 21243, 21243, 6331, 6331, 8571, 8571, 7208, 7208, 5276, 18446, 18446, 16448, 16448, 16216, 16216, 8006, 2568, 2568, 21847, 21847, 2027, 2027, 2695, 2695, 15422, 15422, 5258, 5258, 22002, 22002, 6736, 6736, 391, 391, 13986, 13986, 12666, 12666, 5892, 5892, 3561, 3561, 6184, 6184, 19483, 19483, 22662, 8392, 13067, 13067, 15265, 15265, 19488, 19488, 23599, 23599, 2454, 2454, 11837, 11837, 14039, 14039, 19115, 19115, 10965, 10965, 24538, 24538, 9762, 9762, 5056, 5056, 14948, 8110, 8110, 13773, 20224, 20224, 17412, 17412, 23769, 502, 502, 6910, 6910, 12685, 12685, 23322, 23322, 20872, 206, 206, 21518, 21518, 22361, 22361, 24105, 24105, 23419, 23419, 17868, 17868, 24242, 24242, 15934, 15934, 17247, 17247, 19174, 23792, 23792, 8755, 8755, 21500, 12383, 12383, 22403, 22403, 18141, 18141, 14820, 14820, 7574, 6374, 6374, 23276, 23276, 1678, 1678, 19626, 21020, 1059, 1059, 23052, 23052, 16198, 16198, 9914, 9914, 19541, 19541, 22299, 10817, 10817, 10921, 9789, 9789, 16312, 16312, 11252, 11252, 2693, 2693, 13931, 3627, 3627, 16157, 10173, 10173, 21834, 21834, 18047, 18047, 10230, 10230, 15707, 15707, 21976, 21976, 11494, 11494, 23776, 1306, 6776, 22248, 22248, 9474, 9474, 7526, 7526, 21959, 5530, 5530, 20797, 20797, 3748, 13545, 13545, 663, 663, 1998, 1998, 7994, 17879, 17879, 3304, 3304, 20147, 20147, 21616, 18237, 18237, 13808, 6585, 6585, 17675, 17675, 19965, 11649, 11649, 23938, 23938, 23664, 1636, 1636, 20080, 20080, 17082, 17082, 4737, 4737, 14555, 14555, 13877, 854, 854, 24548, 24548, 5855, 5855, 7392, 22912, 22912, 13949, 13949, 21633, 21556, 21556, 18091, 18091, 5791, 5791, 21919, 21919, 4931, 4931, 19894, 19894, 202, 202, 11447, 11447, 20602, 20602, 12688, 12688, 4389, 4389, 2327, 2327, 8004, 8004, 19315, 7777, 7777, 197, 23509, 1930, 1930, 11774, 11774, 15087, 15087, 22671, 22671, 9339, 9339, 20666, 11589, 11589, 18895, 18895, 15708, 15708, 17043, 17043, 2811, 2811, 23482, 23482, 14243, 14243, 6546, 6546, 1986, 1986, 8338, 8338, 11411, 11411, 2911, 2911, 1734, 1734, 18227, 8680, 8680, 19360, 18343, 18343, 5759, 5759, 23078, 23078, 2385, 2385, 11111, 11111, 4736, 4736, 1802, 1802, 8155, 8155, 8120, 8120, 6616, 6616, 14257, 14257, 14486, 21918, 21918, 20445, 20445, 16646, 16646, 14075, 14075, 9208, 16371, 16371, 11835, 11835, 13168, 13168, 2049, 2049, 5423, 5423, 14589, 14589, 20932, 20932, 19492, 19492, 7158, 7158, 10248, 10248, 7400, 7400, 19554, 19554, 9874, 9874, 15151, 15151, 18639, 18639, 1154, 1154, 4499, 4499, 6295, 6295, 22581, 22581, 12183, 12183, 12874, 12874, 18032, 5539, 9637, 20583, 24829, 24829, 15586, 15586, 2557, 2557, 5592, 5592, 16482, 16482, 2200, 14172, 2961, 2961, 14207, 14207, 21357, 21357, 20817, 20817, 11969, 11969, 2869, 2869, 17340, 17340, 13992, 13992, 24736, 24736, 5699, 5699, 23328, 23328, 20877, 20877, 21295, 21295, 3987, 3987, 22399, 22399, 13446, 13446, 1218, 1218, 20880, 20880, 4735, 4735, 11296, 11296, 4555, 4555, 9146, 9146, 8050, 12757, 12757, 19830, 19830, 17429, 6893, 6893, 18077, 18077, 14373, 14565, 14565, 3436, 8754, 10677, 10677, 5895, 5895, 19738, 19738, 16609, 16609, 15636, 15636, 21277, 21277, 7022, 7022, 9151, 5600, 5600, 7996, 7996, 9007, 9007, 12946, 12946, 24067, 24067, 4642, 4642, 11312, 11312, 7679, 8208, 8208, 23723, 23723, 18589, 18589, 10716, 10716, 17453, 17453, 3444, 3444, 10757, 10757, 14434, 14434, 1060, 1060, 18711, 3420, 3420, 301, 301, 12468, 12468, 16990, 16990, 699, 699, 21472, 21472, 190, 190, 10492, 10492, 17364, 17364, 2975, 2975, 6102, 6102, 19711, 19711, 19778, 19778, 24703, 1816, 1816, 22238, 22238, 23093, 569, 569, 5442, 5442, 1895, 1895, 19117, 19117, 3863, 12913, 12913, 7455, 4014, 11093, 18070, 18070, 3009, 24190, 24190, 16538, 16538, 10729, 1409, 12249, 784, 8096, 7560, 12533, 12533, 7343, 7206, 21980, 21980, 5801, 19190, 16921, 5986, 18225, 18225, 10647, 8716, 23355, 23355, 22009, 19334, 19334, 24376, 12323, 4780, 2368, 12039, 6655, 8173, 4495, 10893, 22386, 22386, 22998, 22998, 13403, 13403, 13121, 13121, 22303, 22303]
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9628571428571429
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.014285714285714235
CCS accuracy on own: 0.017142857142857126
 *** Training on  imdb  and testing on  amazon_polarity
loaded data
Memory used, total: 3.14 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9971428571428571
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9914285714285714
CCS accuracy on own: 0.9742857142857143
 *** Training on  imdb  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.49333333333333335
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.4866666666666667
CCS accuracy on own: 0.037142857142857144
 *** Training on  imdb  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.3564835164835165
Logistic regression accuracy on own: 0.9885714285714285
CCS accuracy on transfer: 0.5342857142857143
CCS accuracy on own: 0.02285714285714291
 *** Training on  imdb  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.4257142857142857
Logistic regression accuracy on own: 0.98
CCS accuracy on transfer: 0.5857142857142857
CCS accuracy on own: 0.9971428571428571
 *** Training on  imdb  and testing on  rte
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.44571428571428573
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.3857142857142857
CCS accuracy on own: 0.9914285714285714
 *** Training on  imdb  and testing on  boolq
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.21428571428571427
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9742857142857143
CCS accuracy on own: 0.98
 *** Training on  imdb  and testing on  qnli
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9942857142857143
Logistic regression accuracy on own: 0.98
CCS accuracy on transfer: 0.9971428571428571
CCS accuracy on own: 0.98
 *** Training on  imdb  and testing on  piqa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.15142857142857144
Logistic regression accuracy on own: 0.9857142857142858
CCS accuracy on transfer: 0.9857142857142858
CCS accuracy on own: 0.9885714285714285
 *** Training on  imdb  and testing on  story-cloze
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.66
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.0
CCS accuracy on own: 0.9942857142857143
 *** Training on  amazon_polarity  and testing on  imdb
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.92
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.9514285714285714
CCS accuracy on own: 0.9685714285714285
 *** Training on  amazon_polarity  and testing on  amazon_polarity
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [944413, 944413, 2116811, 2116811, 686763, 686763, 3390987, 3390987, 1475378, 1475378, 2107512, 2107512, 2905008, 2905008, 2145943, 2145943, 396281, 396281, 1323020, 1323020, 2654810, 2654810, 725191, 725191, 3172937, 3172937, 501503, 501503, 2067911, 2067911, 283071, 283071, 503623, 503623, 1844040, 1844040, 2714694, 2714694, 864845, 864845, 2006811, 2006811, 3134593, 3134593, 2844714, 2844714, 1434636, 1434636, 1907310, 1907310, 3138523, 3138523, 705314, 705314, 3394070, 3394070, 872189, 872189, 3564046, 3564046, 951937, 951937, 2899516, 2899516, 2154955, 2154955, 3578687, 3578687, 1182200, 1182200, 580915, 580915, 1390530, 1390530, 1093956, 1093956, 2257474, 2257474, 1899694, 1899694, 1431041, 1431041, 831460, 831460, 2767807, 2767807, 1948149, 1948149, 3094861, 3094861, 272667, 272667, 3453402, 3453402, 538057, 538057, 2029122, 2029122, 112035, 112035, 1224293, 1224293, 1794679, 1794679, 1503934, 1503934, 2778069, 2778069, 2856239, 2856239, 1390502, 1390502, 340526, 340526, 1216733, 1216733, 2016788, 2016788, 1493149, 1493149, 2994523, 2994523, 1193118, 1193118, 865144, 865144, 1418137, 1418137, 2307306, 2307306, 1710741, 1710741, 3359124, 3359124, 979532, 979532, 1230420, 1230420, 522797, 522797, 991120, 991120, 1674286, 1674286, 3497172, 3497172, 3144158, 3144158, 2365926, 2365926, 910906, 910906, 2458165, 2458165, 1194507, 1194507, 414399, 414399, 2006518, 2006518, 2980869, 2980869, 1690420, 1690420, 1277071, 1277071, 254809, 254809, 3056900, 3056900, 729672, 729672, 1063597, 1063597, 1773799, 1773799, 448781, 448781, 441259, 441259, 2825662, 2825662, 2161513, 2161513, 1967325, 1967325, 2007091, 2007091, 796787, 796787, 1147417, 1147417, 2014772, 2014772, 2801516, 2801516, 1294876, 1294876, 160786, 160786, 541486, 541486, 329095, 329095, 2075414, 2075414, 3016308, 3016308, 3582569, 3582569, 3404194, 3404194, 1527774, 1527774, 1314530, 1314530, 910175, 910175, 3031225, 3031225, 1306884, 1306884, 3245583, 3245583, 734480, 734480, 1861791, 1861791, 121701, 121701, 2589433, 2589433, 3485919, 3485919, 3256499, 3256499, 1054739, 1054739, 980591, 980591, 2945655, 2945655, 1064641, 1064641, 1433043, 1433043, 904401, 904401, 2442752, 2442752, 2594873, 2594873, 248924, 248924, 2800860, 2800860, 2090923, 2090923, 1940711, 1940711, 544517, 544517, 1363307, 1363307, 1823334, 1823334, 3457585, 3457585, 1730933, 1730933, 545389, 545389, 2304087, 2304087, 3218451, 3218451, 3372021, 3372021, 190477, 190477, 1214596, 1214596, 1935272, 1935272, 2019111, 2019111, 300065, 300065, 2567375, 2567375, 2511439, 2511439, 721478, 721478, 179354, 179354, 1664589, 1664589, 2417741, 2417741, 736427, 736427, 1392928, 1392928, 1496608, 1496608, 1417003, 1417003, 2182931, 2182931, 1051636, 1051636, 2747246, 2747246, 3421603, 3421603, 2437126, 2437126, 2642159, 2642159, 2013122, 2013122, 2082214, 2082214, 1563159, 1563159, 2647765, 2647765, 3037253, 3037253, 984943, 984943, 1063127, 1063127, 355431, 355431, 3432150, 3432150, 2581557, 2581557, 15141, 15141, 330057, 330057, 2917199, 2917199, 2815263, 2815263, 289596, 289596, 3561669, 3561669, 574679, 574679, 1693152, 1693152, 1778996, 1778996, 1162111, 1162111, 142770, 142770, 2337099, 2337099, 610999, 610999, 2961434, 2961434, 1944741, 1944741, 3410237, 3410237, 2850065, 2850065, 884094, 884094, 2664812, 2664812, 824255, 824255, 595446, 595446, 1931084, 1931084, 1032564, 1032564, 1810023, 1810023, 1181597, 1181597, 573684, 573684, 1419056, 1419056, 3177640, 3177640, 1105523, 1105523, 513676, 513676, 490913, 490913, 1092963, 1092963, 3078621, 3078621, 2375804, 2375804, 1356312, 1356312, 2730689, 2730689, 2099071, 2099071, 829027, 829027, 140689, 140689, 2130450, 2130450, 1285801, 1285801, 233725, 233725, 2373752, 2373752, 1158175, 1158175, 3229449, 3229449, 824356, 824356, 810672, 810672, 2446677, 2446677, 2368524, 2368524, 2905270, 2905270, 2633360, 2633360, 1580296, 1580296, 1505367, 1505367, 1683371, 1683371, 1441229, 1441229, 1382445, 1382445, 1797511, 1797511, 1737846, 1737846, 646052, 646052, 161298, 161298, 2301374, 2301374, 321243, 321243, 1161133, 1161133, 542301, 542301, 2081530, 2081530, 2988793, 2988793, 2593561, 2593561, 2822887, 2822887, 3077165, 3077165, 1675125, 1675125, 262701, 262701, 2800212, 2800212, 130878, 130878, 2720583, 2720583, 548866, 548866, 2762108, 2762108, 1892508, 1892508, 2693974, 2693974, 2893713, 2893713, 456610, 456610, 2294270, 2294270, 798028, 798028, 2686795, 2686795, 2634414, 2634414, 3343473, 3343473, 1947012, 1947012, 3397094, 3397094, 3534666, 3534666, 2583801, 2583801, 856634, 856634, 2171594, 2171594, 677178, 677178, 2009326, 2009326, 2230878, 2230878, 2655198, 2655198, 1859212, 1859212, 127309, 127309, 690288, 690288, 2610796, 2610796, 2281833, 2281833, 403552, 403552, 1357757, 1357757, 2244430, 2244430, 3189291, 3189291, 1066937, 1066937, 1876343, 1876343, 1123045, 1123045, 1569157, 1569157, 550104, 550104, 1830286, 1830286, 234295, 234295, 616767, 616767, 26819, 26819, 3137953, 3137953, 3530202, 3530202, 8798, 8798, 680503, 680503, 2933279, 2933279, 1474539, 1474539, 1702408, 1702408, 3399528, 3399528, 533703, 533703, 1977165, 1977165, 3553952, 3553952, 3547064, 3547064, 2039436, 2039436, 2731645, 2731645, 1066746, 1066746, 16259, 16259, 2381395, 2381395, 1189297, 1189297, 1177970, 1177970, 1013295, 1013295, 3467130, 3467130, 3317837, 3317837, 1322525, 1322525, 3400327, 3400327, 1091723, 1091723, 74280, 74280, 1225701, 1225701, 368921, 368921, 1670705, 1670705, 1697590, 1697590, 2487655, 2487655, 2173367, 2173367, 1685773, 1685773, 1406085, 1406085, 3418857, 3418857, 3420263, 3420263, 2626301, 2626301, 2029662, 2029662, 2359120, 2359120, 1755864, 1755864, 296508, 296508, 344543, 344543, 1538827, 1821936, 2611212, 2611212, 2321554, 2321554, 567211, 3022575, 3332696, 501854, 501854, 1396538, 1396538, 2787352, 2787352, 1381880, 1381880, 1176741, 3376042, 3376042, 2498544, 2498544, 295673, 3595350, 3595350, 2765453, 525957, 525957, 3120088, 1789718, 1789718, 1952381, 1952381, 2404155, 706443, 2327654, 1830113, 1830113, 2617918, 301951, 301951, 390449, 312499, 495655, 1686279, 1686279, 270855, 270855, 2553447, 1056480, 1056480, 1921486, 2217187, 1793723, 1793723, 1234744, 1234744, 1270242, 1270242, 2362389, 2384214, 2384214, 3087399, 3087399, 2290860, 2811318, 1189042, 1173077, 1173077, 784516, 784516, 616798, 3239436, 3239436]
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9885714285714285
Logistic regression accuracy on own: 0.9942857142857143
CCS accuracy on transfer: 0.9714285714285714
CCS accuracy on own: 0.94
 *** Training on  amazon_polarity  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.5057142857142857
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.3838095238095238
CCS accuracy on own: 0.008571428571428572
 *** Training on  amazon_polarity  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.4096703296703297
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.4175824175824176
CCS accuracy on own: 0.04285714285714286
 *** Training on  amazon_polarity  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.5857142857142857
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.4828571428571429
CCS accuracy on own: 0.02857142857142857
 *** Training on  amazon_polarity  and testing on  rte
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.6314285714285715
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.6171428571428571
CCS accuracy on own: 0.96
 *** Training on  amazon_polarity  and testing on  boolq
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.19714285714285715
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.06000000000000005
CCS accuracy on own: 0.9742857142857143
 *** Training on  amazon_polarity  and testing on  qnli
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 1.0
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 1.0
CCS accuracy on own: 0.9771428571428571
 *** Training on  amazon_polarity  and testing on  piqa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.3028571428571429
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.0
CCS accuracy on own: 0.9542857142857143
 *** Training on  amazon_polarity  and testing on  story-cloze
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.005714285714285714
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 1.0
CCS accuracy on own: 0.008571428571428572
 *** Training on  ag_news  and testing on  imdb
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.38571428571428573
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.6171428571428571
CCS accuracy on own: 0.0019047619047619048
 *** Training on  ag_news  and testing on  amazon_polarity
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.5142857142857142
Logistic regression accuracy on own: 0.9990476190476191
CCS accuracy on transfer: 0.45714285714285713
CCS accuracy on own: 0.002857142857142857
 *** Training on  ag_news  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [70480, 70480, 99252, 99252, 114794, 108987, 108987, 14012, 14012, 102996, 102996, 57498, 68776, 61711, 61711, 42530, 42530, 79267, 79267, 119991, 119991, 18018, 18018, 108434, 108434, 17916, 40376, 40376, 93140, 93140, 110713, 116128, 65046, 65046, 58742, 58742, 85566, 77125, 87519, 87519, 12437, 12437, 62146, 62146, 27618, 50767, 9705, 57146, 57146, 88216, 88216, 80912, 51750, 90956, 44379, 44379, 52682, 52682, 64713, 64713, 105894, 117015, 104869, 56919, 56919, 60384, 60384, 51128, 51128, 1835, 1835, 21283, 21283, 49506, 108101, 108101, 53625, 53625, 35963, 35963, 112172, 9179, 94440, 94440, 106649, 99210, 99210, 11955, 114072, 7198, 67156, 44588, 44588, 11766, 96626, 96626, 53570, 53570, 106827, 69874, 69874, 48679, 48679, 115117, 115117, 5301, 5301, 15144, 13784, 13784, 67959, 8272, 1573, 24419, 82339, 98770, 48555, 5176, 36161, 63440, 108061, 58862, 58862, 15164, 77758, 116723, 25379, 91189, 83552, 83552, 18368, 18368, 89041, 32771, 64950, 40245, 40245, 104302, 104302, 98906, 72792, 43327, 46454, 93787, 46741, 31977, 98200, 98200, 6714, 6714, 106680, 106680, 77237, 14891, 101555, 101555, 52299, 65167, 65124, 93052, 93052, 58639, 40912, 114742, 75452, 75452, 68446, 68446, 83790, 83790, 61516, 44250, 44250, 36116, 83521, 83521, 22151, 22151, 71366, 44297, 44297, 40888, 56195, 56195, 84010, 71016, 74979, 74979, 104674, 54334, 98474, 98474, 68345, 68345, 39761, 26930, 59117, 23095, 77482, 77482, 3991, 23519, 26657, 826, 42625, 82049, 82049, 17801, 17801, 29846, 29846, 39566, 39566, 23157, 23157, 28363, 50559, 50559, 5136, 57937, 17421, 78027, 78027, 7546, 71439, 46623, 16406, 16406, 80485, 9825, 9825, 71823, 71823, 110497, 34173, 107974, 55619, 55619, 83114, 83114, 107071, 107071, 7923, 34374, 34374, 61713, 41411, 41411, 64368, 8316, 109950, 10556, 10058, 104554, 104554, 99987, 99987, 25482, 25482, 44494, 25005, 84671, 89424, 32481, 32481, 28401, 40431, 40431, 64459, 64459, 90473, 111387, 117410, 117410, 78682, 78682, 95637, 95637, 76789, 76789, 48504, 48504, 3223, 3223, 70977, 70977, 108126, 108126, 40149, 12863, 103488, 103488, 29564, 82189, 89624, 22499, 22499, 107619, 89218, 32132, 32132, 4533, 4533, 82962, 82962, 80096, 34409, 81461, 81461, 22987, 10633, 101601, 101601, 56207, 50535, 95661, 3996, 14, 80431, 1674, 37867, 37867, 85537, 57251, 55709, 55709, 17864, 17864, 26321, 24082, 24082, 117734, 40131, 40131, 71493, 4210, 114080, 115663, 64586, 83605, 34851, 26865, 26865, 83606, 4158, 57852, 49339, 101086, 101086, 20572, 4100, 4100, 44469, 44469, 81061, 60861, 60861, 18456, 55803, 65633, 65633, 75019, 75019, 36232, 67323, 67323, 106067, 21788, 21788, 98987, 16092, 16092, 1132, 77850, 77850, 104181, 104181, 88118, 88118, 93316, 97772, 118524, 118524, 13068, 13068, 47401, 47401, 48526, 48526, 58958, 115729, 115729, 76593, 76593, 55041, 55041, 99158, 99158, 104042, 104042, 63372, 63372, 67562, 92099, 92099, 64046, 103669, 103669, 68086, 68086, 96458, 7089, 16623, 49641, 12043, 12043, 66572, 64136, 88052, 86700, 86700, 57061, 57061, 117957, 6122, 6122, 47346, 47346, 97322, 97322, 113993, 16150, 16150, 87630, 87630, 77228, 77228, 12054, 1767, 1767, 4708, 4708, 106657, 57999, 52158, 29292, 29292, 28082, 28082, 34024, 34024, 92270, 108447, 108447, 23461, 23461, 5351, 47031, 47031, 99053, 99053, 82628, 104720, 39718, 39718, 110632, 110632, 90577, 90577, 91212, 100017, 100017, 12777, 12777, 89856, 89856, 8308, 43441, 43441, 113682, 113682, 80865, 13882, 114883, 4714, 4714, 91586, 91586, 43432, 43432, 81289, 81289, 95515, 95515, 110625, 110625, 80166, 17658, 17658, 69245, 69245, 98642, 98642, 105065, 118199, 102579, 102579, 77027, 77027, 50808, 39530, 39530, 8834, 14358, 9872, 58694, 87193, 50321, 50321, 90363, 90363, 73709, 16685, 11333, 116254, 11356, 40584, 40584, 110453, 51362, 51362, 11344, 114491, 44619, 44619, 105534, 107107, 81331, 95279, 1943, 90185, 90185, 60217, 112319, 21021, 21021, 8348, 8348, 77286, 77286, 70921, 16639, 16639, 85030, 64566, 64566, 42011, 114577, 103336, 103336, 104565, 104565, 117105, 18640, 35402, 65088, 60240, 1891, 28259, 63021, 63021, 28987, 28987, 52616, 10683, 10683, 61083, 61083, 9967, 77664, 40194, 100274, 93831, 85873, 62661, 62661, 87738, 87738, 72307, 43452, 12857, 31301, 55900, 31460, 86923, 49800, 49800, 9832, 47408, 47408, 12626, 12626, 57872, 57872, 84021, 84021, 78959, 96939, 96939, 96159, 96159, 16802, 16802, 16333, 35120, 35120, 93621, 22159, 22159, 24660, 24660, 56843, 34519, 94333, 84577, 84577, 44935, 22507, 22507, 71060, 71060, 84271, 84271, 57223, 27675, 27675, 113487, 17673, 17673, 109619, 109619, 35470, 41603, 84825, 84825, 31230, 31230, 14542, 14542, 110563, 61407, 61407, 53821, 35690, 6654, 6654, 67557, 112259, 112259, 85544, 85544, 88264, 89698, 27446, 48484, 44078, 44078, 114824, 4225, 4225, 74745, 74745, 110196, 110196, 81259, 45487, 68676, 11721, 11721, 2587, 108878, 108878, 39437, 18989, 18989, 32726, 70540, 79837, 98215, 98215, 93639, 41168, 41168, 64669, 64669, 73040, 73040, 102114, 71616, 7408, 7408, 4153, 4153, 11055, 19760, 17752, 89729, 89729, 3800, 3800, 66573, 30054, 61816, 26866, 26866, 992, 23696, 60282, 60282, 102814, 102814, 98697, 98697, 73541, 52838, 29400, 82277, 118692, 118692, 17565, 39585, 34833, 12094, 31280, 31280, 46647, 46647, 44378, 44378, 19513, 19513, 154, 95798, 28134, 28134, 108050, 8678, 8678, 6294, 6294, 9574, 35183, 35183, 48747, 48747, 66606, 66606, 18638, 18638, 57194, 47553, 47553, 26082, 26082, 16306, 108371, 7807, 88760, 51342, 32143, 32143, 58414, 58414, 90302, 90302, 24715, 24715, 62054, 72934, 72934, 12202, 12202, 27987, 35740, 116202, 116202, 76848, 76848, 85890, 85890, 53871, 13627, 13627, 99649, 99649, 94294, 94294, 51069, 40409, 94022, 94022, 80635, 111689, 111689, 106948, 106948, 61486, 1611, 31657, 18462, 18462, 76309, 116752, 89299, 38547, 107754, 107754, 29063, 29063, 105454, 82273, 110896, 110896, 79397, 52788, 52788, 42523, 42523, 30284, 30284, 87964, 63996, 63996, 66247, 66247, 13706, 13706, 93614, 10924, 111377, 111377, 15921, 25432, 25432, 118960, 17813, 17813, 104748, 108988, 108988, 65250, 68956, 2068, 39927, 39927, 70342, 70342, 105148, 105148, 30539, 11683, 11683, 85151, 85151, 35674, 35674, 52703, 52703, 58810, 86111, 85343, 85343, 85977, 87114, 11117, 3665, 3665, 119423, 44390, 74884, 63887, 63887, 48266, 48266, 55541, 55541, 64802, 94319, 94319, 7882, 70825, 70825, 13910, 13910, 40566, 40566, 63073, 97519, 36176, 83081, 83081, 30289, 30289, 50411, 112263, 112263, 69626, 69626, 109337, 109337, 15362, 87610, 87610, 96371, 13783, 13783, 44162, 35749, 106369, 3554, 58568, 58568, 110883, 18773, 18773, 73694, 73694, 66550, 46295, 46295, 30331, 30331, 45640, 45640, 64877, 64877, 46969, 42986, 42986, 102017, 102017, 116180, 116180, 7585, 4122, 108196, 16838, 16838, 17301, 23107, 57357, 57357, 88161, 102678, 102678, 55211, 55211, 66025, 66025, 66520, 66520, 17344, 17344, 57202, 57202, 100086, 14959, 14959, 112846, 38751, 1869, 44264, 30268, 30268, 84564, 39606, 13550, 119033, 5702, 78563, 110164, 61745, 98279, 24459, 56782, 87822, 6032, 6032, 1825, 77090, 117798, 117798, 48101, 60109, 12470, 3770, 27268, 29, 30083, 8958, 113806, 113806, 8806, 8806, 32162, 74732, 34889, 27702, 27702, 35777, 52971, 7739, 7739, 24599, 36827, 76821, 96683, 95263, 80210, 80210, 83890, 83890, 96212, 91650, 23039, 119455, 44929, 97367, 97367, 43884, 25146, 45819, 83162, 82632, 31308, 13054, 79606, 107789, 52018, 26250, 14413, 14413, 77391, 38921, 38921, 71123, 71123, 74363, 25785, 56865, 56865, 97400, 96847, 6861, 76340, 13979, 13979, 66833, 113049, 357, 114604, 47201, 54254, 82160, 10796, 10796, 23238, 94176, 50978, 40883, 97393, 85478, 69396, 69396, 110747, 110747, 4447, 20523, 64079, 64823, 49289, 118422, 100271, 104883, 104883, 4849, 24718, 105471, 105471, 87862, 87862, 73002, 60977, 60977, 88325, 27135, 110653, 30262, 89971, 34787, 104478, 15689, 15689, 39860, 39860, 117537, 50344, 108809, 67891, 51658, 97464, 65869, 35330, 80312, 80312, 60064, 60064, 27014, 34563, 15270, 15270, 31279, 98557, 3657, 89422, 107919, 68773, 101635, 1027, 14199, 116854, 111587, 44954, 115157, 115157, 79317, 15120, 56812, 89825, 89825, 5983, 66629, 70325, 70325, 2912, 47879, 47879, 21873, 21873, 14332, 16564, 77795, 107716, 20526, 65481, 65481, 52775, 86649, 16006, 21643, 21643]
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.9952380952380953
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.9885714285714285
CCS accuracy on own: 0.9923809523809524
 *** Training on  ag_news  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
Loaded dataset: imdb
Dataset({
    features: ['text', 'label'],
    num_rows: 25000
})
Loaded dataset: amazon_polarity
Dataset({
    features: ['label', 'title', 'content', 'text'],
    num_rows: 3600000
})
Loaded dataset: ag_news
Dataset({
    features: ['text', 'label'],
    num_rows: 120000
})
Loaded dataset: dbpedia_14
Dataset({
    features: ['label', 'title', 'content', 'text'],
    num_rows: 560000
})
Loaded dataset: super_glue/copa
Dataset({
    features: ['text', 'text1', 'text2', 'question', 'idx', 'label', '__index_level_0__'],
    num_rows: 500
})
Loaded dataset: super_glue/rte
Dataset({
    features: ['text', 'text1', 'idx', 'label'],
    num_rows: 2490
})
Loaded dataset: boolq
Dataset({
    features: ['text1', 'label', 'text'],
    num_rows: 9427
})
Loaded dataset: glue/qnli
Dataset({
    features: ['text', 'text1', 'label', 'idx'],
    num_rows: 104743
})
Loaded dataset: piqa
Dataset({
    features: ['text', 'text1', 'text2', 'label'],
    num_rows: 16113
})
Loaded dataset: chenxwh/gen-storycloze
Dataset({
    features: ['story_id', 'input_sentence_1', 'input_sentence_2', 'input_sentence_3', 'input_sentence_4', 'text', 'text1', 'text2', 'answer_right_ending', 'text_right_ending', 'text_wrong_ending', 'label'],
    num_rows: 1785
})
[2023-07-06 20:33:04,196] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Models loaded successfully!
 **** Loaded model:  deberta
 *** Training on  imdb  and testing on  imdb
loaded data
Memory used, total: 2.92 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [23654, 23654, 15795, 15795, 860, 860, 5390, 5390, 21575, 21575, 11964, 11964, 11284, 11284, 22118, 22118, 6265, 6265, 16850, 16850, 4426, 4426, 21962, 21962, 14423, 11363, 11363, 16023, 16023, 8322, 8322, 1685, 1685, 769, 769, 23333, 23333, 2433, 2433, 5311, 5311, 5051, 5051, 6420, 6420, 17568, 17568, 20939, 20939, 19769, 19769, 6396, 6396, 8666, 8666, 18942, 18942, 24233, 24233, 18431, 18431, 2747, 2747, 189, 189, 19118, 19118, 3005, 3005, 21042, 21042, 1899, 1899, 24118, 24118, 1267, 17912, 17912, 11394, 11394, 3556, 3556, 3890, 3890, 8838, 14502, 14502, 21777, 21777, 10627, 10627, 8792, 10555, 10555, 10253, 10253, 8433, 8433, 10233, 10233, 11016, 11016, 23897, 23897, 2612, 2612, 23425, 23425, 22619, 22619, 21870, 21870, 23483, 23483, 15787, 15787, 17159, 17159, 12206, 12206, 8226, 8226, 14541, 14541, 3152, 3152, 1585, 1585, 3943, 3943, 23939, 23939, 19457, 19457, 1021, 1021, 11653, 11653, 10805, 10805, 13417, 13417, 20227, 20227, 7989, 7989, 9692, 9692, 12990, 12990, 6873, 6873, 5675, 5675, 161, 161, 4297, 4297, 995, 995, 11534, 11534, 7629, 7629, 1016, 1016, 24253, 24253, 22823, 24276, 24276, 23247, 23247, 24300, 24300, 8529, 8529, 17262, 17262, 9268, 9268, 21271, 21271, 12185, 12185, 21243, 21243, 6331, 6331, 8571, 8571, 7208, 7208, 5276, 18446, 18446, 16448, 16448, 16216, 16216, 8006, 2568, 2568, 21847, 21847, 2027, 2027, 2695, 2695, 15422, 15422, 5258, 5258, 22002, 22002, 6736, 6736, 391, 391, 13986, 13986, 12666, 12666, 5892, 5892, 3561, 3561, 6184, 6184, 19483, 19483, 22662, 8392, 13067, 13067, 15265, 15265, 19488, 19488, 23599, 23599, 2454, 2454, 11837, 11837, 14039, 14039, 19115, 19115, 10965, 10965, 24538, 24538, 9762, 9762, 5056, 5056, 14948, 8110, 8110, 13773, 20224, 20224, 17412, 17412, 23769, 502, 502, 6910, 6910, 12685, 12685, 23322, 23322, 20872, 206, 206, 21518, 21518, 22361, 22361, 24105, 24105, 23419, 23419, 17868, 17868, 24242, 24242, 15934, 15934, 17247, 17247, 19174, 23792, 23792, 8755, 8755, 21500, 12383, 12383, 22403, 22403, 18141, 18141, 14820, 14820, 7574, 6374, 6374, 23276, 23276, 1678, 1678, 19626, 21020, 1059, 1059, 23052, 23052, 16198, 16198, 9914, 9914, 19541, 19541, 22299, 10817, 10817, 10921, 9789, 9789, 16312, 16312, 11252, 11252, 2693, 2693, 13931, 3627, 3627, 16157, 10173, 10173, 21834, 21834, 18047, 18047, 10230, 10230, 15707, 15707, 21976, 21976, 11494, 11494, 23776, 1306, 6776, 22248, 22248, 9474, 9474, 7526, 7526, 21959, 5530, 5530, 20797, 20797, 3748, 13545, 13545, 663, 663, 1998, 1998, 7994, 17879, 17879, 3304, 3304, 20147, 20147, 21616, 18237, 18237, 13808, 6585, 6585, 17675, 17675, 19965, 11649, 11649, 23938, 23938, 23664, 1636, 1636, 20080, 20080, 17082, 17082, 4737, 4737, 14555, 14555, 13877, 854, 854, 24548, 24548, 5855, 5855, 7392, 22912, 22912, 13949, 13949, 21633, 21556, 21556, 18091, 18091, 5791, 5791, 21919, 21919, 4931, 4931, 19894, 19894, 202, 202, 11447, 11447, 20602, 20602, 12688, 12688, 4389, 4389, 2327, 2327, 8004, 8004, 19315, 7777, 7777, 197, 23509, 1930, 1930, 11774, 11774, 15087, 15087, 22671, 22671, 9339, 9339, 20666, 11589, 11589, 18895, 18895, 15708, 15708, 17043, 17043, 2811, 2811, 23482, 23482, 14243, 14243, 6546, 6546, 1986, 1986, 8338, 8338, 11411, 11411, 2911, 2911, 1734, 1734, 18227, 8680, 8680, 19360, 18343, 18343, 5759, 5759, 23078, 23078, 2385, 2385, 11111, 11111, 4736, 4736, 1802, 1802, 8155, 8155, 8120, 8120, 6616, 6616, 14257, 14257, 14486, 21918, 21918, 20445, 20445, 16646, 16646, 14075, 14075, 9208, 16371, 16371, 11835, 11835, 13168, 13168, 2049, 2049, 5423, 5423, 14589, 14589, 20932, 20932, 19492, 19492, 7158, 7158, 10248, 10248, 7400, 7400, 19554, 19554, 9874, 9874, 15151, 15151, 18639, 18639, 1154, 1154, 4499, 4499, 6295, 6295, 22581, 22581, 12183, 12183, 12874, 12874, 18032, 5539, 9637, 20583, 24829, 24829, 15586, 15586, 2557, 2557, 5592, 5592, 16482, 16482, 2200, 14172, 2961, 2961, 14207, 14207, 21357, 21357, 20817, 20817, 11969, 11969, 2869, 2869, 17340, 17340, 13992, 13992, 24736, 24736, 5699, 5699, 23328, 23328, 20877, 20877, 21295, 21295, 3987, 3987, 22399, 22399, 13446, 13446, 1218, 1218, 20880, 20880, 4735, 4735, 11296, 11296, 4555, 4555, 9146, 9146, 8050, 12757, 12757, 19830, 19830, 17429, 6893, 6893, 18077, 18077, 14373, 14565, 14565, 3436, 8754, 10677, 10677, 5895, 5895, 19738, 19738, 16609, 16609, 15636, 15636, 21277, 21277, 7022, 7022, 9151, 5600, 5600, 7996, 7996, 9007, 9007, 12946, 12946, 24067, 24067, 4642, 4642, 11312, 11312, 7679, 8208, 8208, 23723, 23723, 18589, 18589, 10716, 10716, 17453, 17453, 3444, 3444, 10757, 10757, 14434, 14434, 1060, 1060, 18711, 3420, 3420, 301, 301, 12468, 12468, 16990, 16990, 699, 699, 21472, 21472, 190, 190, 10492, 10492, 17364, 17364, 2975, 2975, 6102, 6102, 19711, 19711, 19778, 19778, 24703, 1816, 1816, 22238, 22238, 23093, 569, 569, 5442, 5442, 1895, 1895, 19117, 19117, 3863, 12913, 12913, 7455, 4014, 11093, 18070, 18070, 3009, 24190, 24190, 16538, 16538, 10729, 1409, 12249, 784, 8096, 7560, 12533, 12533, 7343, 7206, 21980, 21980, 5801, 19190, 16921, 5986, 18225, 18225, 10647, 8716, 23355, 23355, 22009, 19334, 19334, 24376, 12323, 4780, 2368, 12039, 6655, 8173, 4495, 10893, 22386, 22386, 22998, 22998, 13403, 13403, 13121, 13121, 22303, 22303]
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.49274725274725273
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.42923076923076925
CCS accuracy on own: 0.0
 *** Training on  ag_news  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9628571428571429
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9942857142857143
CCS accuracy on own: 0.9885714285714285
 *** Training on  imdb  and testing on  amazon_polarity
loaded data
Memory used, total: 3.14 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9971428571428571
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9914285714285714
CCS accuracy on own: 0.9857142857142858
 *** Training on  imdb  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.49333333333333335
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.5228571428571429
CCS accuracy on own: 0.03142857142857143
 *** Training on  imdb  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.3564835164835165
Logistic regression accuracy on own: 0.9885714285714285
CCS accuracy on transfer: 0.4646153846153846
CCS accuracy on own: 0.98
 *** Training on  imdb  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.4257142857142857
Logistic regression accuracy on own: 0.98
CCS accuracy on transfer: 0.31142857142857144
CCS accuracy on own: 0.002857142857142857
 *** Training on  imdb  and testing on  rte
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.44571428571428573
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.6
CCS accuracy on own: 0.008571428571428572
 *** Training on  imdb  and testing on  boolq
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.21428571428571427
Logistic regression accuracy on own: 0.9828571428571429
CCS accuracy on transfer: 0.9685714285714285
CCS accuracy on own: 0.98
 *** Training on  imdb  and testing on  qnli
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9942857142857143
Logistic regression accuracy on own: 0.98
CCS accuracy on transfer: 0.0
CCS accuracy on own: 0.011428571428571455
 *** Training on  imdb  and testing on  piqa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.15142857142857144
Logistic regression accuracy on own: 0.9857142857142858
CCS accuracy on transfer: 0.9685714285714285
CCS accuracy on own: 0.9942857142857143
 *** Training on  imdb  and testing on  story-cloze
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.66
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.0
CCS accuracy on own: 0.9942857142857143
 *** Training on  amazon_polarity  and testing on  imdb
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.92
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.04285714285714286
CCS accuracy on own: 0.03142857142857143
 *** Training on  amazon_polarity  and testing on  amazon_polarity
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [944413, 944413, 2116811, 2116811, 686763, 686763, 3390987, 3390987, 1475378, 1475378, 2107512, 2107512, 2905008, 2905008, 2145943, 2145943, 396281, 396281, 1323020, 1323020, 2654810, 2654810, 725191, 725191, 3172937, 3172937, 501503, 501503, 2067911, 2067911, 283071, 283071, 503623, 503623, 1844040, 1844040, 2714694, 2714694, 864845, 864845, 2006811, 2006811, 3134593, 3134593, 2844714, 2844714, 1434636, 1434636, 1907310, 1907310, 3138523, 3138523, 705314, 705314, 3394070, 3394070, 872189, 872189, 3564046, 3564046, 951937, 951937, 2899516, 2899516, 2154955, 2154955, 3578687, 3578687, 1182200, 1182200, 580915, 580915, 1390530, 1390530, 1093956, 1093956, 2257474, 2257474, 1899694, 1899694, 1431041, 1431041, 831460, 831460, 2767807, 2767807, 1948149, 1948149, 3094861, 3094861, 272667, 272667, 3453402, 3453402, 538057, 538057, 2029122, 2029122, 112035, 112035, 1224293, 1224293, 1794679, 1794679, 1503934, 1503934, 2778069, 2778069, 2856239, 2856239, 1390502, 1390502, 340526, 340526, 1216733, 1216733, 2016788, 2016788, 1493149, 1493149, 2994523, 2994523, 1193118, 1193118, 865144, 865144, 1418137, 1418137, 2307306, 2307306, 1710741, 1710741, 3359124, 3359124, 979532, 979532, 1230420, 1230420, 522797, 522797, 991120, 991120, 1674286, 1674286, 3497172, 3497172, 3144158, 3144158, 2365926, 2365926, 910906, 910906, 2458165, 2458165, 1194507, 1194507, 414399, 414399, 2006518, 2006518, 2980869, 2980869, 1690420, 1690420, 1277071, 1277071, 254809, 254809, 3056900, 3056900, 729672, 729672, 1063597, 1063597, 1773799, 1773799, 448781, 448781, 441259, 441259, 2825662, 2825662, 2161513, 2161513, 1967325, 1967325, 2007091, 2007091, 796787, 796787, 1147417, 1147417, 2014772, 2014772, 2801516, 2801516, 1294876, 1294876, 160786, 160786, 541486, 541486, 329095, 329095, 2075414, 2075414, 3016308, 3016308, 3582569, 3582569, 3404194, 3404194, 1527774, 1527774, 1314530, 1314530, 910175, 910175, 3031225, 3031225, 1306884, 1306884, 3245583, 3245583, 734480, 734480, 1861791, 1861791, 121701, 121701, 2589433, 2589433, 3485919, 3485919, 3256499, 3256499, 1054739, 1054739, 980591, 980591, 2945655, 2945655, 1064641, 1064641, 1433043, 1433043, 904401, 904401, 2442752, 2442752, 2594873, 2594873, 248924, 248924, 2800860, 2800860, 2090923, 2090923, 1940711, 1940711, 544517, 544517, 1363307, 1363307, 1823334, 1823334, 3457585, 3457585, 1730933, 1730933, 545389, 545389, 2304087, 2304087, 3218451, 3218451, 3372021, 3372021, 190477, 190477, 1214596, 1214596, 1935272, 1935272, 2019111, 2019111, 300065, 300065, 2567375, 2567375, 2511439, 2511439, 721478, 721478, 179354, 179354, 1664589, 1664589, 2417741, 2417741, 736427, 736427, 1392928, 1392928, 1496608, 1496608, 1417003, 1417003, 2182931, 2182931, 1051636, 1051636, 2747246, 2747246, 3421603, 3421603, 2437126, 2437126, 2642159, 2642159, 2013122, 2013122, 2082214, 2082214, 1563159, 1563159, 2647765, 2647765, 3037253, 3037253, 984943, 984943, 1063127, 1063127, 355431, 355431, 3432150, 3432150, 2581557, 2581557, 15141, 15141, 330057, 330057, 2917199, 2917199, 2815263, 2815263, 289596, 289596, 3561669, 3561669, 574679, 574679, 1693152, 1693152, 1778996, 1778996, 1162111, 1162111, 142770, 142770, 2337099, 2337099, 610999, 610999, 2961434, 2961434, 1944741, 1944741, 3410237, 3410237, 2850065, 2850065, 884094, 884094, 2664812, 2664812, 824255, 824255, 595446, 595446, 1931084, 1931084, 1032564, 1032564, 1810023, 1810023, 1181597, 1181597, 573684, 573684, 1419056, 1419056, 3177640, 3177640, 1105523, 1105523, 513676, 513676, 490913, 490913, 1092963, 1092963, 3078621, 3078621, 2375804, 2375804, 1356312, 1356312, 2730689, 2730689, 2099071, 2099071, 829027, 829027, 140689, 140689, 2130450, 2130450, 1285801, 1285801, 233725, 233725, 2373752, 2373752, 1158175, 1158175, 3229449, 3229449, 824356, 824356, 810672, 810672, 2446677, 2446677, 2368524, 2368524, 2905270, 2905270, 2633360, 2633360, 1580296, 1580296, 1505367, 1505367, 1683371, 1683371, 1441229, 1441229, 1382445, 1382445, 1797511, 1797511, 1737846, 1737846, 646052, 646052, 161298, 161298, 2301374, 2301374, 321243, 321243, 1161133, 1161133, 542301, 542301, 2081530, 2081530, 2988793, 2988793, 2593561, 2593561, 2822887, 2822887, 3077165, 3077165, 1675125, 1675125, 262701, 262701, 2800212, 2800212, 130878, 130878, 2720583, 2720583, 548866, 548866, 2762108, 2762108, 1892508, 1892508, 2693974, 2693974, 2893713, 2893713, 456610, 456610, 2294270, 2294270, 798028, 798028, 2686795, 2686795, 2634414, 2634414, 3343473, 3343473, 1947012, 1947012, 3397094, 3397094, 3534666, 3534666, 2583801, 2583801, 856634, 856634, 2171594, 2171594, 677178, 677178, 2009326, 2009326, 2230878, 2230878, 2655198, 2655198, 1859212, 1859212, 127309, 127309, 690288, 690288, 2610796, 2610796, 2281833, 2281833, 403552, 403552, 1357757, 1357757, 2244430, 2244430, 3189291, 3189291, 1066937, 1066937, 1876343, 1876343, 1123045, 1123045, 1569157, 1569157, 550104, 550104, 1830286, 1830286, 234295, 234295, 616767, 616767, 26819, 26819, 3137953, 3137953, 3530202, 3530202, 8798, 8798, 680503, 680503, 2933279, 2933279, 1474539, 1474539, 1702408, 1702408, 3399528, 3399528, 533703, 533703, 1977165, 1977165, 3553952, 3553952, 3547064, 3547064, 2039436, 2039436, 2731645, 2731645, 1066746, 1066746, 16259, 16259, 2381395, 2381395, 1189297, 1189297, 1177970, 1177970, 1013295, 1013295, 3467130, 3467130, 3317837, 3317837, 1322525, 1322525, 3400327, 3400327, 1091723, 1091723, 74280, 74280, 1225701, 1225701, 368921, 368921, 1670705, 1670705, 1697590, 1697590, 2487655, 2487655, 2173367, 2173367, 1685773, 1685773, 1406085, 1406085, 3418857, 3418857, 3420263, 3420263, 2626301, 2626301, 2029662, 2029662, 2359120, 2359120, 1755864, 1755864, 296508, 296508, 344543, 344543, 1538827, 1821936, 2611212, 2611212, 2321554, 2321554, 567211, 3022575, 3332696, 501854, 501854, 1396538, 1396538, 2787352, 2787352, 1381880, 1381880, 1176741, 3376042, 3376042, 2498544, 2498544, 295673, 3595350, 3595350, 2765453, 525957, 525957, 3120088, 1789718, 1789718, 1952381, 1952381, 2404155, 706443, 2327654, 1830113, 1830113, 2617918, 301951, 301951, 390449, 312499, 495655, 1686279, 1686279, 270855, 270855, 2553447, 1056480, 1056480, 1921486, 2217187, 1793723, 1793723, 1234744, 1234744, 1270242, 1270242, 2362389, 2384214, 2384214, 3087399, 3087399, 2290860, 2811318, 1189042, 1173077, 1173077, 784516, 784516, 616798, 3239436, 3239436]
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.9885714285714285
Logistic regression accuracy on own: 0.9942857142857143
CCS accuracy on transfer: 0.9628571428571429
CCS accuracy on own: 0.9285714285714286
 *** Training on  amazon_polarity  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.5057142857142857
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.6066666666666667
CCS accuracy on own: 0.9914285714285714
 *** Training on  amazon_polarity  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.4096703296703297
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.5929670329670329
CCS accuracy on own: 0.9571428571428572
 *** Training on  amazon_polarity  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.5857142857142857
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.4342857142857143
CCS accuracy on own: 0.02857142857142858
 *** Training on  amazon_polarity  and testing on  rte
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.6314285714285715
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 0.5971428571428572
CCS accuracy on own: 0.9628571428571429
 *** Training on  amazon_polarity  and testing on  boolq
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.19714285714285715
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.11714285714285715
CCS accuracy on own: 0.9742857142857143
 *** Training on  amazon_polarity  and testing on  qnli
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 1.0
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 1.0
CCS accuracy on own: 0.9771428571428571
 *** Training on  amazon_polarity  and testing on  piqa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.3028571428571429
Logistic regression accuracy on own: 0.9914285714285714
CCS accuracy on transfer: 0.0
CCS accuracy on own: 0.9628571428571429
 *** Training on  amazon_polarity  and testing on  story-cloze
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (350, 1536)
Shape of y_train:  (350,)
Logistic regression accuracy on transfer: 0.005714285714285714
Logistic regression accuracy on own: 0.9971428571428571
CCS accuracy on transfer: 1.0
CCS accuracy on own: 0.008571428571428572
 *** Training on  ag_news  and testing on  imdb
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.38571428571428573
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.6599999999999999
CCS accuracy on own: 0.0019047619047618536
 *** Training on  ag_news  and testing on  amazon_polarity
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.5142857142857142
Logistic regression accuracy on own: 0.9990476190476191
CCS accuracy on transfer: 0.43714285714285717
CCS accuracy on own: 0.002857142857142857
 *** Training on  ag_news  and testing on  ag_news
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: [70480, 70480, 99252, 99252, 114794, 108987, 108987, 14012, 14012, 102996, 102996, 57498, 68776, 61711, 61711, 42530, 42530, 79267, 79267, 119991, 119991, 18018, 18018, 108434, 108434, 17916, 40376, 40376, 93140, 93140, 110713, 116128, 65046, 65046, 58742, 58742, 85566, 77125, 87519, 87519, 12437, 12437, 62146, 62146, 27618, 50767, 9705, 57146, 57146, 88216, 88216, 80912, 51750, 90956, 44379, 44379, 52682, 52682, 64713, 64713, 105894, 117015, 104869, 56919, 56919, 60384, 60384, 51128, 51128, 1835, 1835, 21283, 21283, 49506, 108101, 108101, 53625, 53625, 35963, 35963, 112172, 9179, 94440, 94440, 106649, 99210, 99210, 11955, 114072, 7198, 67156, 44588, 44588, 11766, 96626, 96626, 53570, 53570, 106827, 69874, 69874, 48679, 48679, 115117, 115117, 5301, 5301, 15144, 13784, 13784, 67959, 8272, 1573, 24419, 82339, 98770, 48555, 5176, 36161, 63440, 108061, 58862, 58862, 15164, 77758, 116723, 25379, 91189, 83552, 83552, 18368, 18368, 89041, 32771, 64950, 40245, 40245, 104302, 104302, 98906, 72792, 43327, 46454, 93787, 46741, 31977, 98200, 98200, 6714, 6714, 106680, 106680, 77237, 14891, 101555, 101555, 52299, 65167, 65124, 93052, 93052, 58639, 40912, 114742, 75452, 75452, 68446, 68446, 83790, 83790, 61516, 44250, 44250, 36116, 83521, 83521, 22151, 22151, 71366, 44297, 44297, 40888, 56195, 56195, 84010, 71016, 74979, 74979, 104674, 54334, 98474, 98474, 68345, 68345, 39761, 26930, 59117, 23095, 77482, 77482, 3991, 23519, 26657, 826, 42625, 82049, 82049, 17801, 17801, 29846, 29846, 39566, 39566, 23157, 23157, 28363, 50559, 50559, 5136, 57937, 17421, 78027, 78027, 7546, 71439, 46623, 16406, 16406, 80485, 9825, 9825, 71823, 71823, 110497, 34173, 107974, 55619, 55619, 83114, 83114, 107071, 107071, 7923, 34374, 34374, 61713, 41411, 41411, 64368, 8316, 109950, 10556, 10058, 104554, 104554, 99987, 99987, 25482, 25482, 44494, 25005, 84671, 89424, 32481, 32481, 28401, 40431, 40431, 64459, 64459, 90473, 111387, 117410, 117410, 78682, 78682, 95637, 95637, 76789, 76789, 48504, 48504, 3223, 3223, 70977, 70977, 108126, 108126, 40149, 12863, 103488, 103488, 29564, 82189, 89624, 22499, 22499, 107619, 89218, 32132, 32132, 4533, 4533, 82962, 82962, 80096, 34409, 81461, 81461, 22987, 10633, 101601, 101601, 56207, 50535, 95661, 3996, 14, 80431, 1674, 37867, 37867, 85537, 57251, 55709, 55709, 17864, 17864, 26321, 24082, 24082, 117734, 40131, 40131, 71493, 4210, 114080, 115663, 64586, 83605, 34851, 26865, 26865, 83606, 4158, 57852, 49339, 101086, 101086, 20572, 4100, 4100, 44469, 44469, 81061, 60861, 60861, 18456, 55803, 65633, 65633, 75019, 75019, 36232, 67323, 67323, 106067, 21788, 21788, 98987, 16092, 16092, 1132, 77850, 77850, 104181, 104181, 88118, 88118, 93316, 97772, 118524, 118524, 13068, 13068, 47401, 47401, 48526, 48526, 58958, 115729, 115729, 76593, 76593, 55041, 55041, 99158, 99158, 104042, 104042, 63372, 63372, 67562, 92099, 92099, 64046, 103669, 103669, 68086, 68086, 96458, 7089, 16623, 49641, 12043, 12043, 66572, 64136, 88052, 86700, 86700, 57061, 57061, 117957, 6122, 6122, 47346, 47346, 97322, 97322, 113993, 16150, 16150, 87630, 87630, 77228, 77228, 12054, 1767, 1767, 4708, 4708, 106657, 57999, 52158, 29292, 29292, 28082, 28082, 34024, 34024, 92270, 108447, 108447, 23461, 23461, 5351, 47031, 47031, 99053, 99053, 82628, 104720, 39718, 39718, 110632, 110632, 90577, 90577, 91212, 100017, 100017, 12777, 12777, 89856, 89856, 8308, 43441, 43441, 113682, 113682, 80865, 13882, 114883, 4714, 4714, 91586, 91586, 43432, 43432, 81289, 81289, 95515, 95515, 110625, 110625, 80166, 17658, 17658, 69245, 69245, 98642, 98642, 105065, 118199, 102579, 102579, 77027, 77027, 50808, 39530, 39530, 8834, 14358, 9872, 58694, 87193, 50321, 50321, 90363, 90363, 73709, 16685, 11333, 116254, 11356, 40584, 40584, 110453, 51362, 51362, 11344, 114491, 44619, 44619, 105534, 107107, 81331, 95279, 1943, 90185, 90185, 60217, 112319, 21021, 21021, 8348, 8348, 77286, 77286, 70921, 16639, 16639, 85030, 64566, 64566, 42011, 114577, 103336, 103336, 104565, 104565, 117105, 18640, 35402, 65088, 60240, 1891, 28259, 63021, 63021, 28987, 28987, 52616, 10683, 10683, 61083, 61083, 9967, 77664, 40194, 100274, 93831, 85873, 62661, 62661, 87738, 87738, 72307, 43452, 12857, 31301, 55900, 31460, 86923, 49800, 49800, 9832, 47408, 47408, 12626, 12626, 57872, 57872, 84021, 84021, 78959, 96939, 96939, 96159, 96159, 16802, 16802, 16333, 35120, 35120, 93621, 22159, 22159, 24660, 24660, 56843, 34519, 94333, 84577, 84577, 44935, 22507, 22507, 71060, 71060, 84271, 84271, 57223, 27675, 27675, 113487, 17673, 17673, 109619, 109619, 35470, 41603, 84825, 84825, 31230, 31230, 14542, 14542, 110563, 61407, 61407, 53821, 35690, 6654, 6654, 67557, 112259, 112259, 85544, 85544, 88264, 89698, 27446, 48484, 44078, 44078, 114824, 4225, 4225, 74745, 74745, 110196, 110196, 81259, 45487, 68676, 11721, 11721, 2587, 108878, 108878, 39437, 18989, 18989, 32726, 70540, 79837, 98215, 98215, 93639, 41168, 41168, 64669, 64669, 73040, 73040, 102114, 71616, 7408, 7408, 4153, 4153, 11055, 19760, 17752, 89729, 89729, 3800, 3800, 66573, 30054, 61816, 26866, 26866, 992, 23696, 60282, 60282, 102814, 102814, 98697, 98697, 73541, 52838, 29400, 82277, 118692, 118692, 17565, 39585, 34833, 12094, 31280, 31280, 46647, 46647, 44378, 44378, 19513, 19513, 154, 95798, 28134, 28134, 108050, 8678, 8678, 6294, 6294, 9574, 35183, 35183, 48747, 48747, 66606, 66606, 18638, 18638, 57194, 47553, 47553, 26082, 26082, 16306, 108371, 7807, 88760, 51342, 32143, 32143, 58414, 58414, 90302, 90302, 24715, 24715, 62054, 72934, 72934, 12202, 12202, 27987, 35740, 116202, 116202, 76848, 76848, 85890, 85890, 53871, 13627, 13627, 99649, 99649, 94294, 94294, 51069, 40409, 94022, 94022, 80635, 111689, 111689, 106948, 106948, 61486, 1611, 31657, 18462, 18462, 76309, 116752, 89299, 38547, 107754, 107754, 29063, 29063, 105454, 82273, 110896, 110896, 79397, 52788, 52788, 42523, 42523, 30284, 30284, 87964, 63996, 63996, 66247, 66247, 13706, 13706, 93614, 10924, 111377, 111377, 15921, 25432, 25432, 118960, 17813, 17813, 104748, 108988, 108988, 65250, 68956, 2068, 39927, 39927, 70342, 70342, 105148, 105148, 30539, 11683, 11683, 85151, 85151, 35674, 35674, 52703, 52703, 58810, 86111, 85343, 85343, 85977, 87114, 11117, 3665, 3665, 119423, 44390, 74884, 63887, 63887, 48266, 48266, 55541, 55541, 64802, 94319, 94319, 7882, 70825, 70825, 13910, 13910, 40566, 40566, 63073, 97519, 36176, 83081, 83081, 30289, 30289, 50411, 112263, 112263, 69626, 69626, 109337, 109337, 15362, 87610, 87610, 96371, 13783, 13783, 44162, 35749, 106369, 3554, 58568, 58568, 110883, 18773, 18773, 73694, 73694, 66550, 46295, 46295, 30331, 30331, 45640, 45640, 64877, 64877, 46969, 42986, 42986, 102017, 102017, 116180, 116180, 7585, 4122, 108196, 16838, 16838, 17301, 23107, 57357, 57357, 88161, 102678, 102678, 55211, 55211, 66025, 66025, 66520, 66520, 17344, 17344, 57202, 57202, 100086, 14959, 14959, 112846, 38751, 1869, 44264, 30268, 30268, 84564, 39606, 13550, 119033, 5702, 78563, 110164, 61745, 98279, 24459, 56782, 87822, 6032, 6032, 1825, 77090, 117798, 117798, 48101, 60109, 12470, 3770, 27268, 29, 30083, 8958, 113806, 113806, 8806, 8806, 32162, 74732, 34889, 27702, 27702, 35777, 52971, 7739, 7739, 24599, 36827, 76821, 96683, 95263, 80210, 80210, 83890, 83890, 96212, 91650, 23039, 119455, 44929, 97367, 97367, 43884, 25146, 45819, 83162, 82632, 31308, 13054, 79606, 107789, 52018, 26250, 14413, 14413, 77391, 38921, 38921, 71123, 71123, 74363, 25785, 56865, 56865, 97400, 96847, 6861, 76340, 13979, 13979, 66833, 113049, 357, 114604, 47201, 54254, 82160, 10796, 10796, 23238, 94176, 50978, 40883, 97393, 85478, 69396, 69396, 110747, 110747, 4447, 20523, 64079, 64823, 49289, 118422, 100271, 104883, 104883, 4849, 24718, 105471, 105471, 87862, 87862, 73002, 60977, 60977, 88325, 27135, 110653, 30262, 89971, 34787, 104478, 15689, 15689, 39860, 39860, 117537, 50344, 108809, 67891, 51658, 97464, 65869, 35330, 80312, 80312, 60064, 60064, 27014, 34563, 15270, 15270, 31279, 98557, 3657, 89422, 107919, 68773, 101635, 1027, 14199, 116854, 111587, 44954, 115157, 115157, 79317, 15120, 56812, 89825, 89825, 5983, 66629, 70325, 70325, 2912, 47879, 47879, 21873, 21873, 14332, 16564, 77795, 107716, 20526, 65481, 65481, 52775, 86649, 16006, 21643, 21643]
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.9952380952380953
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.008571428571428563
CCS accuracy on own: 0.004761904761904745
 *** Training on  ag_news  and testing on  dbpedia_14
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.49274725274725273
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.4112087912087912
CCS accuracy on own: 0.0019047619047619048
 *** Training on  ag_news  and testing on  copa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.03428571428571429
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.017142857142857126
CCS accuracy on own: 0.9961904761904762
 *** Training on  ag_news  and testing on  rte
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.7828571428571428
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.9028571428571428
CCS accuracy on own: 0.9895238095238095
 *** Training on  ag_news  and testing on  boolq
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.9257142857142857
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.5
CCS accuracy on own: 0.007619047619047636
 *** Training on  ag_news  and testing on  qnli
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, train
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
got hidden states, test
Memory used, total: 3.15 GB
Shape of x_train:  (1050, 1536)
Shape of y_train:  (1050,)
Logistic regression accuracy on transfer: 0.35428571428571426
Logistic regression accuracy on own: 1.0
CCS accuracy on transfer: 0.002857142857142857
CCS accuracy on own: 0.9971428571428571
 *** Training on  ag_news  and testing on  piqa
loaded data
Memory used, total: 3.15 GB
neg_labels_limit: 175
pos_labels_limit: 175
intial used_idx: []
