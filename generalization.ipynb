{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8378/1448159700.py:8: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_8378/1448159700.py:9: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Replicate ITI results, make sure ITI utils and probing utils work right\n",
    "\n",
    "#%%\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the TransformerLens code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")\n",
    "    \n",
    "import plotly.io as pio\n",
    "# pio.renderers.default = \"png\"\n",
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.probing_utils import ModelActs\n",
    "from utils.dataset_utils import CounterFact_Dataset, TQA_MC_Dataset, EZ_Dataset\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "from utils.iti_utils import patch_iti\n",
    "\n",
    "from utils.analytics_utils import plot_probe_accuracies, plot_norm_diffs, plot_cosine_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-xl into HookedTransformer\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\"\n",
    "print(\"loading model\")\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-xl\",\n",
    "    center_unembed=False,\n",
    "    center_writing_weights=False,\n",
    "    fold_ln=False,\n",
    "    refactor_factored_attn_matrices=True,\n",
    "    device=device,\n",
    ")\n",
    "# model.to(device)\n",
    "print(\"done\")\n",
    "model.set_use_attn_result(True)\n",
    "model.cfg.total_heads = model.cfg.n_heads * model.cfg.n_layers\n",
    "\n",
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--elem_tf-64ec49cd4cd5be64/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4421bd7d6c1645729709cd30db21c6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--ms_tf-728c6138d8f6c1c5/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdf8be647494456985f6f9e925b6629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--misconceptions_tf-131f43b181040ffa/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b232ed034b84ce9abdd55f337c43fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--kindergarten_tf-e3c53e366bc35ec1/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824ae7c2b473403a9d41c19f9fedf7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--hs_tf-9f911d9357ff2386/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdce8bd2f47e43619668ce1e07c9182e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--truthfulness-4380c84abeab6c8f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c566a6d317b4084ad389a4f34743aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--truthfulness-4380c84abeab6c8f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183db6086dee4a1e8713063b1e1b0cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--truthfulness-4380c84abeab6c8f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1384c4586dac42eebd5700c89dd2ff27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--truthfulness-4380c84abeab6c8f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ee287c2f374c2b852e37d658d8d3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--truthfulness-4380c84abeab6c8f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd6b27fcb964eafa706c2a8ae9d85ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/notrichardren___parquet/notrichardren--truthfulness-4380c84abeab6c8f/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960aa3bf5f7e466598821a08628ad87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.dataset_utils import MS_Dataset, Elem_Dataset, MisCons_Dataset, Kinder_Dataset, HS_Dataset, BoolQ_Question_Dataset, TruthfulQA_Tfn, CounterFact_Tfn, Fever_Tfn, BoolQ_Tfn, Creak_Tfn, CommonClaim_Tfn\n",
    "random_seed = 5\n",
    "\n",
    "datanames = [\"MS\", \"Elem\", \"MisCons\", \"Kinder\", \"HS\", \"TruthfulQA\", \"CounterFact\", \"Fever\", \"Creak\", \"BoolQ\", \"CommonClaim\"]\n",
    "\n",
    "ms_data = MS_Dataset(model.tokenizer, questions=True)\n",
    "elem_data = Elem_Dataset(model.tokenizer, questions=True)\n",
    "miscons_data = MisCons_Dataset(model.tokenizer, questions=True)\n",
    "kinder_data = Kinder_Dataset(model.tokenizer, questions=True)\n",
    "hs_data = HS_Dataset(model.tokenizer, questions=True)\n",
    "# boolq_data = BoolQ_Question_Dataset(model.tokenizer)\n",
    "\n",
    "tqa_data = TruthfulQA_Tfn(model.tokenizer, questions=True)\n",
    "cfact_data = CounterFact_Tfn(model.tokenizer, questions=True)\n",
    "fever_data = Fever_Tfn(model.tokenizer, questions=True)\n",
    "boolq_data = BoolQ_Tfn(model.tokenizer, questions=True)\n",
    "creak_data = Creak_Tfn(model.tokenizer, questions=True)\n",
    "commonclaim_data = CommonClaim_Tfn(model.tokenizer, questions=True)\n",
    "\n",
    "datasets = {\"MS\": ms_data, \"Elem\": elem_data, \"MisCons\": miscons_data, \"Kinder\": kinder_data, \"HS\": hs_data, \"TruthfulQA\": tqa_data, \"CounterFact\": cfact_data, \"Fever\": fever_data, \"Creak\": creak_data, \"BoolQ\": boolq_data, \"CommonClaim\": commonclaim_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for MS, prompts in form ['Is the below statement true or false? Cows produce milk. Answer:']\n",
      "for Elem, prompts in form ['Is the below statement true or false? Cows are herbivores. Answer:']\n",
      "for MisCons, prompts in form ['Is the below statement true or false? Dolphins are fish. Answer:']\n",
      "for Kinder, prompts in form ['Is the below statement true or false? Bats sleep during the day. Answer:']\n",
      "for HS, prompts in form ['Is the below statement true or false? Elephants are the largest land animals. Answer:']\n",
      "for TruthfulQA, prompts in form ['Is the below statement true or false? What happens to you if you eat watermelon seeds? You grow watermelons in your stomach. Answer:']\n",
      "for CounterFact, prompts in form ['Is the below statement true or false? Toko Yasuda, the piano. Answer:']\n",
      "for Fever, prompts in form ['Is the below statement true or false? The Boston Celtics play their home games at TD Garden. Answer:']\n",
      "for Creak, prompts in form ['Is the below statement true or false? The crack in the Liberty Bell sets it apart from other famous bells. Answer:']\n",
      "for BoolQ, prompts in form ['Is the below statement true or false? There is not a series of seven serial murders called Night of the Living Dead. Answer:']\n",
      "for CommonClaim, prompts in form ['Is the below statement true or false? A study was recently done on identical twins and the result was interesting. Answer:']\n"
     ]
    }
   ],
   "source": [
    "for dataname in datanames:\n",
    "    print(f\"for {dataname}, prompts in form {model.tokenizer.batch_decode(datasets[dataname].all_prompts[5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 1200, 64]), torch.Size([200, 1200, 64]), torch.Size([800, 1200]), torch.Size([200, 1200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:26<00:00, 45.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 1200, 64]), torch.Size([200, 1200, 64]), torch.Size([800, 1200]), torch.Size([200, 1200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:29<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 1200, 64]), torch.Size([200, 1200, 64]), torch.Size([800, 1200]), torch.Size([200, 1200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [00:37<00:00, 32.34it/s]\n"
     ]
    }
   ],
   "source": [
    "n_acts = 1000\n",
    "acts = {}\n",
    "\n",
    "for name in datanames:\n",
    "    acts[name] = ModelActs(model, datasets[name], act_types=[\"z\", \"mlp_out\", \"resid_post\", \"resid_pre\", \"logits\"])\n",
    "    model_acts: ModelActs = acts[name]\n",
    "    # model_acts.gen_acts(N=n_acts, id=f\"{name}_gpt2xl_{n_acts}\")\n",
    "    model_acts.load_acts(id=f\"{name}_gpt2xl_{n_acts}\", load_probes=False)\n",
    "    model_acts.train_probes(\"z\", max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:45<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [02:21<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:23<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [02:03<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [02:16<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [02:34<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 48, 1600]), torch.Size([200, 48, 1600]), torch.Size([800, 48]), torch.Size([200, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 22/48 [01:06<01:18,  3.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>act_type = <span style=\"color: #808000; text-decoration-color: #808000\">\"mlp_out\"</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> probe_idx, probe_source <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(datanames):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>acts[probe_source].train_probes(act_type, max_iter=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10000</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>probe_transfer_accs = torch.zeros(size=(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(datanames), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(datanames)))                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> probe_idx, probe_source <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(datanames):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/deep_learning/iti_capstone/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">probing_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">221</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_probes</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>X_train, X_test, y_train, y_test, indices_train, indices_test = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_train_t   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>X_train.shape<span style=\"color: #808000; text-decoration-color: #808000\">}, {</span>X_test.shape<span style=\"color: #808000; text-decoration-color: #808000\">}, {</span>y_train.shape<span style=\"color: #808000; text-decoration-color: #808000\">}, {</span>y_test.shape<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>221 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>probes, probe_accs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_probes(formatted_acts.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], X_train, X_test   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">222 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.X_tests[act_type] = X_test                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.y_tests[act_type] = y_test                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/deep_learning/iti_capstone/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">probing_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">197</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_train_probes</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>X_train_head = X_train[:,i,:]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>X_test_head = X_test[:,i,:]                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>197 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>clf = LogisticRegression(max_iter=max_iter).fit(X_train_head.detach().numpy(   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>y_pred = clf.predict(X_train_head)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>y_val_pred = clf.predict(X_test_head.detach().numpy())                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_logistic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">129</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1288 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1289 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>n_threads = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1291 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>fold_coefs_ = Parallel(n_jobs=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.n_jobs, verbose=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.verbose, prefer=prefer)(  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1292 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_func(                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1293 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>X,                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1294 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>y,                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">63</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>(_with_config(delayed_func, config), args, kwargs)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> delayed_func, args, kwargs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> iterable                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 63 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(iterable_with_config)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 # remove when https://github.com/joblib/joblib/issues/1071 is fixed</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1085</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1082 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># was very quick and its callback already dispatched all the</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1083 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># remaining jobs.</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1084 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._iterating = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1085 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dispatch_one_batch(iterator):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1086 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._iterating = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._original_iterator <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1087 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dispatch_one_batch(iterator):                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">901</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dispatch_one_batch</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 898 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># No more tasks available in the iterator: tell caller to stop.</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 899 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 900 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 901 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dispatch(tasks)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 902 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 903 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_print</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, msg, msg_args):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">819</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_dispatch</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 816 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>cb = BatchCompletionCallBack(dispatch_timestamp, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(batch), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 817 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._lock:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>job_idx = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._jobs)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 819 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>job = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backend.apply_async(batch, callback=cb)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 820 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># A job can complete so quickly than its callback is</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 821 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># called before we get here, causing self._jobs to</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 822 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># grow. To ensure correct results ordering, .insert is</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_parallel_backends.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">208</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_async</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">205 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">206 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_async</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func, callback=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">207 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Schedule a func to be run\"\"\"</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>208 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>result = ImmediateResult(func)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> callback:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>callback(result)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> result                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_parallel_backends.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">597</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">594 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, batch):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">595 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Don't delay the application, to avoid keeping the input</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">596 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># arguments in memory</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>597 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.results = batch()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">598 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">599 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">600 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.results                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">288</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Set the default nested backend to self._backend but do not set the</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 286 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># change the default number of processes to -1</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 287 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> parallel_backend(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backend, n_jobs=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._n_jobs):                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 288 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [func(*args, **kwargs)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 289 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> func, args, kwargs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.items]                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 291 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__reduce__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">288</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Set the default nested backend to self._backend but do not set the</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 286 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># change the default number of processes to -1</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 287 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> parallel_backend(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backend, n_jobs=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._n_jobs):                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 288 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [func(*args, **kwargs)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 289 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> func, args, kwargs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.items]                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 291 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__reduce__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">123</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>config = {}                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> config_context(**config):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>123 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.function(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_logistic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">450</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_logistic_regression_path</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 447 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>iprint = [-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">50</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">100</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">101</span>][                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 448 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>np.searchsorted(np.array([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>]), verbose)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 449 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>]                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 450 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>opt_res = optimize.minimize(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 451 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>func,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 452 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>w0,                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 453 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>method=<span style=\"color: #808000; text-decoration-color: #808000\">\"L-BFGS-B\"</span>,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_minimize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">696</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">minimize</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 693 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 694 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │    </span>**options)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 695 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> meth == <span style=\"color: #808000; text-decoration-color: #808000\">'l-bfgs-b'</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 696 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>res = _minimize_lbfgsb(fun, x0, args, jac, bounds,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 697 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │      </span>callback=callback, **options)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 698 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> meth == <span style=\"color: #808000; text-decoration-color: #808000\">'tnc'</span>:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 699 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_lbfgsb_py.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">359</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_minimize_lbfgsb</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Note that interruptions due to maxfun are postponed</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># until the completion of the current minimization iteration.</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Overwrite f and g:</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>359 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>f, g = func_and_grad(x)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> task_str.startswith(<span style=\"color: #808000; text-decoration-color: #808000\">b'NEW_X'</span>):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">361 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># new iteration</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">362 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>n_iterations += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_differentiable_functi</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ons.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">285</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fun_and_grad</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fun_and_grad</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> np.array_equal(x, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.x):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">284 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_x_impl(x)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>285 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_fun()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_grad()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">287 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.f, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.g                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">288 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_differentiable_functi</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ons.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">251</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_update_fun</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_update_fun</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">250 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.f_updated:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>251 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_fun_impl()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">252 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.f_updated = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">253 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">254 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_update_grad</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_differentiable_functi</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ons.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">155</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update_fun</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fx                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">update_fun</span>():                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>155 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.f = fun_wrapped(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.x)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_fun_impl = update_fun                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_fun()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_differentiable_functi</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ons.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">137</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fun_wrapped</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Send a copy because the user may overwrite it.</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Overwriting results in undefined behaviour because</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># fun(self.x) will change self.x, with the two no longer linked.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>137 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>fx = fun(np.copy(x), *args)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Make sure the function returns a true scalar</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> np.isscalar(fx):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_optimize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">76</span> in     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x, *args):                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  75 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\" returns the function value \"\"\"</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  76 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compute_if_needed(x, *args)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._value                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  78 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">derivative</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x, *args):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_optimize.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_compute_if_needed</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_compute_if_needed</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x, *args):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> np.all(x == <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.x) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.jac <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.x = np.asarray(x).copy()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>fg = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fun(x, *args)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.jac = fg[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._value = fg[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  73 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_linear_loss.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">274</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loss_gradient</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">271 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>n_dof = n_features + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fit_intercept)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> raw_prediction <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>274 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>weights, intercept, raw_prediction = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight_intercept_raw(coef, X)        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">275 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>weights, intercept = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight_intercept(coef)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_linear_loss.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">162</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">weight_intercept_raw</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>weights, intercept = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight_intercept(coef)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.base_loss.is_multiclass:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>162 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>raw_prediction = X @ weights + intercept                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># weights has shape (n_classes, n_dof)</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>raw_prediction = X @ weights.T + intercept  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># ndarray, likely C-contiguous</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m5\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0mact_type = \u001b[33m\"\u001b[0m\u001b[33mmlp_out\u001b[0m\u001b[33m\"\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfor\u001b[0m probe_idx, probe_source \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(datanames):                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 \u001b[2m│   \u001b[0macts[probe_source].train_probes(act_type, max_iter=\u001b[94m10000\u001b[0m)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0mprobe_transfer_accs = torch.zeros(size=(\u001b[96mlen\u001b[0m(datanames), \u001b[96mlen\u001b[0m(datanames)))                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[94mfor\u001b[0m probe_idx, probe_source \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(datanames):                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/deep_learning/iti_capstone/utils/\u001b[0m\u001b[1;33mprobing_utils.py\u001b[0m:\u001b[94m221\u001b[0m in \u001b[92mtrain_probes\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   \u001b[0mX_train, X_test, y_train, y_test, indices_train, indices_test = \u001b[96mself\u001b[0m.get_train_t   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mX_train.shape\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m{\u001b[0mX_test.shape\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m{\u001b[0my_train.shape\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m{\u001b[0my_test.shape\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m221 \u001b[2m│   │   \u001b[0mprobes, probe_accs = \u001b[96mself\u001b[0m._train_probes(formatted_acts.shape[\u001b[94m1\u001b[0m], X_train, X_test   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m222 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.X_tests[act_type] = X_test                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.y_tests[act_type] = y_test                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/deep_learning/iti_capstone/utils/\u001b[0m\u001b[1;33mprobing_utils.py\u001b[0m:\u001b[94m197\u001b[0m in \u001b[92m_train_probes\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   │   │   \u001b[0mX_train_head = X_train[:,i,:]                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   │   \u001b[0mX_test_head = X_test[:,i,:]                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m197 \u001b[2m│   │   │   \u001b[0mclf = LogisticRegression(max_iter=max_iter).fit(X_train_head.detach().numpy(   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   │   \u001b[0my_pred = clf.predict(X_train_head)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   \u001b[0my_val_pred = clf.predict(X_test_head.detach().numpy())                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/\u001b[0m\u001b[1;33m_logistic.py\u001b[0m:\u001b[94m129\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1\u001b[0m in \u001b[92mfit\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1288 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1289 \u001b[0m\u001b[2m│   │   │   \u001b[0mn_threads = \u001b[94m1\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1290 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1291 \u001b[2m│   │   \u001b[0mfold_coefs_ = Parallel(n_jobs=\u001b[96mself\u001b[0m.n_jobs, verbose=\u001b[96mself\u001b[0m.verbose, prefer=prefer)(  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1292 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_func(                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1293 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mX,                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1294 \u001b[0m\u001b[2m│   │   │   │   \u001b[0my,                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/utils/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m63\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__call__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   │   \u001b[0m(_with_config(delayed_func, config), args, kwargs)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m delayed_func, args, kwargs \u001b[95min\u001b[0m iterable                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().\u001b[92m__call__\u001b[0m(iterable_with_config)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m# remove when https://github.com/joblib/joblib/issues/1071 is fixed\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m1085\u001b[0m in \u001b[92m__call__\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1082 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# was very quick and its callback already dispatched all the\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1083 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# remaining jobs.\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1084 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._iterating = \u001b[94mFalse\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1085 \u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.dispatch_one_batch(iterator):                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1086 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._iterating = \u001b[96mself\u001b[0m._original_iterator \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1087 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1088 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[96mself\u001b[0m.dispatch_one_batch(iterator):                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m901\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mdispatch_one_batch\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 898 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# No more tasks available in the iterator: tell caller to stop.\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 899 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mFalse\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 900 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 901 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._dispatch(tasks)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 902 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mTrue\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 903 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 904 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_print\u001b[0m(\u001b[96mself\u001b[0m, msg, msg_args):                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m819\u001b[0m in \u001b[92m_dispatch\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 816 \u001b[0m\u001b[2m│   │   \u001b[0mcb = BatchCompletionCallBack(dispatch_timestamp, \u001b[96mlen\u001b[0m(batch), \u001b[96mself\u001b[0m)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 817 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m._lock:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m│   │   │   \u001b[0mjob_idx = \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m._jobs)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 819 \u001b[2m│   │   │   \u001b[0mjob = \u001b[96mself\u001b[0m._backend.apply_async(batch, callback=cb)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 820 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# A job can complete so quickly than its callback is\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 821 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# called before we get here, causing self._jobs to\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 822 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# grow. To ensure correct results ordering, .insert is\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33m_parallel_backends.py\u001b[0m:\u001b[94m208\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mapply_async\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m205 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m206 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mapply_async\u001b[0m(\u001b[96mself\u001b[0m, func, callback=\u001b[94mNone\u001b[0m):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m207 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Schedule a func to be run\"\"\"\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m208 \u001b[2m│   │   \u001b[0mresult = ImmediateResult(func)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m callback:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   \u001b[0mcallback(result)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m211 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m result                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33m_parallel_backends.py\u001b[0m:\u001b[94m597\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m594 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, batch):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m595 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Don't delay the application, to avoid keeping the input\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m596 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# arguments in memory\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m597 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.results = batch()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m598 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m599 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget\u001b[0m(\u001b[96mself\u001b[0m):                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m600 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.results                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m288\u001b[0m in \u001b[92m__call__\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 285 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Set the default nested backend to self._backend but do not set the\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 286 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# change the default number of processes to -1\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 287 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m parallel_backend(\u001b[96mself\u001b[0m._backend, n_jobs=\u001b[96mself\u001b[0m._n_jobs):                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 288 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m [func(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 289 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m func, args, kwargs \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.items]                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 290 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 291 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__reduce__\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/joblib/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m288\u001b[0m in \u001b[92m<listcomp>\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 285 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Set the default nested backend to self._backend but do not set the\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 286 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# change the default number of processes to -1\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 287 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m parallel_backend(\u001b[96mself\u001b[0m._backend, n_jobs=\u001b[96mself\u001b[0m._n_jobs):                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 288 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m [func(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 289 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m func, args, kwargs \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.items]                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 290 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 291 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__reduce__\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/utils/\u001b[0m\u001b[1;33mparallel.py\u001b[0m:\u001b[94m123\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__call__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig = {}                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m config_context(**config):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m123 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.function(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/\u001b[0m\u001b[1;33m_logistic.py\u001b[0m:\u001b[94m450\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m_logistic_regression_path\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 447 \u001b[0m\u001b[2m│   │   │   \u001b[0miprint = [-\u001b[94m1\u001b[0m, \u001b[94m50\u001b[0m, \u001b[94m1\u001b[0m, \u001b[94m100\u001b[0m, \u001b[94m101\u001b[0m][                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 448 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnp.searchsorted(np.array([\u001b[94m0\u001b[0m, \u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m3\u001b[0m]), verbose)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 449 \u001b[0m\u001b[2m│   │   │   \u001b[0m]                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 450 \u001b[2m│   │   │   \u001b[0mopt_res = optimize.minimize(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 451 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfunc,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 452 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mw0,                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 453 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmethod=\u001b[33m\"\u001b[0m\u001b[33mL-BFGS-B\u001b[0m\u001b[33m\"\u001b[0m,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_minimize.py\u001b[0m:\u001b[94m696\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mminimize\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 693 \u001b[0m\u001b[2m│   │   \u001b[0mres = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 694 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │    \u001b[0m**options)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 695 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m meth == \u001b[33m'\u001b[0m\u001b[33ml-bfgs-b\u001b[0m\u001b[33m'\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 696 \u001b[2m│   │   \u001b[0mres = _minimize_lbfgsb(fun, x0, args, jac, bounds,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 697 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0mcallback=callback, **options)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 698 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m meth == \u001b[33m'\u001b[0m\u001b[33mtnc\u001b[0m\u001b[33m'\u001b[0m:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 699 \u001b[0m\u001b[2m│   │   \u001b[0mres = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_lbfgsb_py.py\u001b[0m:\u001b[94m359\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_minimize_lbfgsb\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Note that interruptions due to maxfun are postponed\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# until the completion of the current minimization iteration.\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Overwrite f and g:\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m359 \u001b[2m│   │   │   \u001b[0mf, g = func_and_grad(x)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m360 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m task_str.startswith(\u001b[33mb\u001b[0m\u001b[33m'\u001b[0m\u001b[33mNEW_X\u001b[0m\u001b[33m'\u001b[0m):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m361 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# new iteration\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   │   \u001b[0mn_iterations += \u001b[94m1\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_differentiable_functi\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mons.py\u001b[0m:\u001b[94m285\u001b[0m in \u001b[92mfun_and_grad\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfun_and_grad\u001b[0m(\u001b[96mself\u001b[0m, x):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m np.array_equal(x, \u001b[96mself\u001b[0m.x):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m284 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._update_x_impl(x)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m285 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._update_fun()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._update_grad()                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m287 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.f, \u001b[96mself\u001b[0m.g                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_differentiable_functi\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mons.py\u001b[0m:\u001b[94m251\u001b[0m in \u001b[92m_update_fun\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_update_fun\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m250 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.f_updated:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m251 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._update_fun_impl()                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.f_updated = \u001b[94mTrue\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m254 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_update_grad\u001b[0m(\u001b[96mself\u001b[0m):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_differentiable_functi\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mons.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mupdate_fun\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m fx                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mupdate_fun\u001b[0m():                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = fun_wrapped(\u001b[96mself\u001b[0m.x)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._update_fun_impl = update_fun                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._update_fun()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_differentiable_functi\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mons.py\u001b[0m:\u001b[94m137\u001b[0m in \u001b[92mfun_wrapped\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Send a copy because the user may overwrite it.\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Overwriting results in undefined behaviour because\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m137 \u001b[2m│   │   │   \u001b[0mfx = fun(np.copy(x), *args)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Make sure the function returns a true scalar\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m np.isscalar(fx):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_optimize.py\u001b[0m:\u001b[94m76\u001b[0m in     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__call__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  74 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, x, *args):                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  75 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\" returns the function value \"\"\"\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  76 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._compute_if_needed(x, *args)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  77 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._value                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  78 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  79 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mderivative\u001b[0m(\u001b[96mself\u001b[0m, x, *args):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/scipy/optimize/\u001b[0m\u001b[1;33m_optimize.py\u001b[0m:\u001b[94m70\u001b[0m in     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_compute_if_needed\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  67 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_compute_if_needed\u001b[0m(\u001b[96mself\u001b[0m, x, *args):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  68 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m np.all(x == \u001b[96mself\u001b[0m.x) \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._value \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.jac \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  69 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.x = np.asarray(x).copy()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m  70 \u001b[2m│   │   │   \u001b[0mfg = \u001b[96mself\u001b[0m.fun(x, *args)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  71 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.jac = fg[\u001b[94m1\u001b[0m]                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  72 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._value = fg[\u001b[94m0\u001b[0m]                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m  73 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/\u001b[0m\u001b[1;33m_linear_loss.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m274\u001b[0m in \u001b[92mloss_gradient\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m271 \u001b[0m\u001b[2m│   │   \u001b[0mn_dof = n_features + \u001b[96mint\u001b[0m(\u001b[96mself\u001b[0m.fit_intercept)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m raw_prediction \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m274 \u001b[2m│   │   │   \u001b[0mweights, intercept, raw_prediction = \u001b[96mself\u001b[0m.weight_intercept_raw(coef, X)        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m275 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   │   \u001b[0mweights, intercept = \u001b[96mself\u001b[0m.weight_intercept(coef)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phil/.conda/envs/iti-cap/lib/python3.8/site-packages/sklearn/linear_model/\u001b[0m\u001b[1;33m_linear_loss.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m162\u001b[0m in \u001b[92mweight_intercept_raw\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mweights, intercept = \u001b[96mself\u001b[0m.weight_intercept(coef)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.base_loss.is_multiclass:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   │   \u001b[0mraw_prediction = X @ weights + intercept                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# weights has shape (n_classes, n_dof)\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   │   \u001b[0mraw_prediction = X @ weights.T + intercept  \u001b[2m# ndarray, likely C-contiguous\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Check Probe Transfer Accuracy\n",
    "act_type = \"z\"\n",
    "\n",
    "# for probe_idx, probe_source in enumerate(datanames):\n",
    "    # acts[probe_source].train_probes(act_type, max_iter=10000)\n",
    " \n",
    "probe_transfer_accs = torch.zeros(size=(len(datanames), len(datanames)))\n",
    "for probe_idx, probe_source in enumerate(datanames):\n",
    "    # acts[probe_source].train_probes(act_type)\n",
    "    for data_idx, data_source in enumerate(datanames):\n",
    "        accs = acts[probe_source].get_transfer_acc(act_type, acts[data_source])\n",
    "        probe_transfer_accs[probe_idx, data_idx] = accs.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.DataFrame(probe_transfer_accs, columns=datanames, index=datanames)\n",
    "\n",
    "plt.figure(figsize=(10, 7))  # Set the figure size\n",
    "sns.heatmap(df, annot=True, cmap='viridis')  # Create a heatmap\n",
    "plt.title(f\"Generalization of Probes on {act_type} across Datasets, Means of Probe Accuracies \")\n",
    "plt.xlabel(\"Probe Testing Dataset\")\n",
    "plt.ylabel(\"Probe Training Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.analytics_utils as analytics\n",
    "\n",
    "for name in datanames:\n",
    "    analytics.plot_probe_accuracies(acts[name]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get difference in positive and negative logits\n",
    "\n",
    "# Should be same number of positive and negative tokens\n",
    "positive_str_tokens = [\"Yes\", \"yes\", \" Yes\", \" yes\", \"True\", \"true\", \" True\", \" true\"]\n",
    "negative_str_tokens = [\"No\", \"no\", \" No\", \" no\", \"False\", \"false\", \" False\", \" false\"]\n",
    "\n",
    "positive_tokens = [model.tokenizer(token).input_ids[0] for token in positive_str_tokens]\n",
    "negative_tokens = [model.tokenizer(token).input_ids[0] for token in negative_str_tokens]\n",
    "\n",
    "def tot_logit_diff(model_acts, use_probs=False, eps=1e-8, test_only=True, act_type=\"z\", check_balanced_output=False):\n",
    "\n",
    "    if test_only:\n",
    "        sample_labels = np.array(model_acts.dataset.all_labels)[model_acts.indices_tests[act_type]] # labels\n",
    "        positive_sum = torch.empty(size=(model_acts.indices_tests[act_type].shape[0],))\n",
    "        negative_sum = torch.empty(size=(model_acts.indices_tests[act_type].shape[0],))\n",
    "        meta_indices = np.array([np.where(model_acts.indices == i)[0][0] for i in model_acts.indices_tests[\"z\"]])\n",
    "\n",
    "    \n",
    "    else:\n",
    "        sample_labels = np.array(model_acts.dataset.all_labels)[model_acts.indices] # labels\n",
    "        positive_sum = torch.empty(size=(model_acts.indices.shape[0],))\n",
    "        negative_sum = torch.empty(size=(model_acts.indices.shape[0],))\n",
    "        meta_indices = np.arange(model_acts.indices.shape[0],)\n",
    "    \n",
    "    check_positive_prop = 0\n",
    "\n",
    "    for idx, logits in enumerate(model_acts.stored_acts[\"logits\"][meta_indices]):\n",
    "\n",
    "        # if answer to statement is True, correct tokens is Yes, yes, ..., true\n",
    "        correct_tokens = positive_tokens if sample_labels[idx] else negative_tokens\n",
    "        incorrect_tokens = negative_tokens if sample_labels[idx] else positive_tokens\n",
    "        \n",
    "        check_positive_prop += 1 if sample_labels[idx] else 0\n",
    "\n",
    "        if check_balanced_output:\n",
    "            correct_tokens = positive_tokens\n",
    "            incorrect_tokens = negative_tokens\n",
    "\n",
    "\n",
    "        if use_probs:\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            positive_prob = probs[0, correct_tokens].sum(dim=-1)\n",
    "            negative_prob = probs[0, incorrect_tokens].sum(dim=-1)\n",
    "            positive_sum[idx] = positive_prob #/ (positive_prob + negative_prob + eps)\n",
    "            negative_sum[idx] = negative_prob #/ (positive_prob + negative_prob + eps)\n",
    "\n",
    "        else:\n",
    "            positive_sum[idx] = logits[0, correct_tokens].sum(dim=-1)\n",
    "            negative_sum[idx] = logits[0, incorrect_tokens].sum(dim=-1)\n",
    "\n",
    "    print(f\"proportion of positive labels is {check_positive_prop/len(meta_indices)}\")\n",
    "    return positive_sum, negative_sum\n",
    "\n",
    "for name in datanames:\n",
    "    positive_sum, negative_sum = tot_logit_diff(acts[name], use_probs=True, test_only=True, check_balanced_output=False)\n",
    "    print(f\"{name}, {positive_sum.mean()}, {negative_sum.mean()}, {(positive_sum.mean() - negative_sum.mean())*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(datasets[\"TruthfulQA\"].sample(100)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_datapoint_probe_acc(model_acts, point, label, act_type):\n",
    "    \"\"\"\n",
    "    Get probe accuracy on one particular datapoint (one sample)\n",
    "    Label is 0 or 1 (true or false)\n",
    "    Datapoint is shape (num_probes, d_probe) (e.g. stored_acts[\"z\"][i])\n",
    "    \"\"\"\n",
    "    probe_accs = []\n",
    "    # print(f\"{point.shape=}\")\n",
    "    for idx, probe in enumerate(model_acts.probes[act_type]):\n",
    "        y_pred = probe.predict_proba(point[idx].numpy().reshape(1, -1))\n",
    "        # print(f\"{label=}, {y_pred=}\")\n",
    "        # print(y_pred)\n",
    "        # probe_accs.append(accuracy_score([label], y_pred))\n",
    "        if label == 1.0:\n",
    "            # then 1st is good\n",
    "            probe_accs.append(y_pred[0][1])\n",
    "        else:\n",
    "            probe_accs.append(y_pred[0][0])\n",
    "    return probe_accs\n",
    "\n",
    "print(f\"Average stored probe acc is {acts['MS'].probe_accs['z'].mean()}\")\n",
    "all_accs = 0\n",
    "for i in range(100):\n",
    "    point = einops.rearrange(acts[\"MS\"].stored_acts[\"z\"][i], \"n_l n_h d_p -> (n_l n_h) d_p\")\n",
    "    label = acts[\"MS\"].dataset.all_labels[acts[\"MS\"].indices[i]]\n",
    "    probe_accs = get_datapoint_probe_acc(acts[\"MS\"], point, label, \"z\")\n",
    "    all_accs += sum(probe_accs)/len(probe_accs)\n",
    "print(all_accs / 100)\n",
    "\n",
    "\n",
    "\n",
    "# \"True or False: The first president of the United States was George Washington.\" label: True\n",
    "# \"True or False: The first president of the United States was John Adam.\" label: False\n",
    "\n",
    "\n",
    "# \"Tell me if the prompt is True or False \\n The first president of the United States was George Washington. \\n Print \"true\" fi it's true and \"fFalse\" if it's false\" label: True\n",
    "# \"True or False: The first president of the United States was John Adam.\" label: False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.iti_utils import patch_iti\n",
    "n_acts = 1000\n",
    "\n",
    "iti_acts = {}\n",
    "for name in datanames:\n",
    "    iti_acts[name] = ModelActs(model, datasets[name], act_types=[\"z\", \"mlp_out\", \"resid_post\", \"resid_pre\",\"logits\"])\n",
    "    cache_interventions = torch.zeros(size=(model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head))\n",
    "    patch_iti(model, acts[name], topk=50, alpha=20, use_MMD=True, model_device=\"cuda\", cache_interventions=cache_interventions, train_only=True)\n",
    "    model_acts: ModelActs = iti_acts[name]\n",
    "\n",
    "    # if name == \"BoolQ\":\n",
    "    model_acts.gen_acts(N=n_acts, id=f\"iti_{name}_gpt2xl_{n_acts}\", indices=acts[name].indices)\n",
    "    # else:\n",
    "    #     model_acts.load_acts(id=f\"iti_{name}_gpt2xl_{n_acts}\", load_probes=False)\n",
    "    # model_acts.train_probes(\"z\", max_iter=1000)\n",
    "    model_acts.indices_trains = acts[name].indices_trains\n",
    "    model_acts.indices_tests = acts[name].indices_tests\n",
    "\n",
    "    print(cache_interventions.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph of model accuracy differential vs probe accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors=['b', 'r']\n",
    "names=[\"default\", \"iti\"]\n",
    "probe_acc_dict = {}\n",
    "for idx, act_list in enumerate([acts, iti_acts]):\n",
    "    model_acc_diffs = []\n",
    "    probe_accs = []\n",
    "    for name in datanames:\n",
    "        positive_sum, negative_sum = tot_logit_diff(act_list[name], use_probs=True)\n",
    "        model_acc_diffs.append(positive_sum.mean() - negative_sum.mean())\n",
    "\n",
    "        probe_accs.append(acts[name].probe_accs[\"z\"].mean())\n",
    "        probe_acc_dict[name] = round(acts[name].probe_accs[\"z\"].mean(), 3)\n",
    "\n",
    "    plt.scatter(probe_accs, model_acc_diffs, c=colors[idx], label=names[idx])\n",
    "\n",
    "plt.title(\"Model performance on datasets before/after ITI\")\n",
    "plt.xlabel(\"Probe Accuracy\")\n",
    "plt.ylabel(\"Model Accuracy Differential\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(probe_acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts[\"TruthfulQA\"].y_tests[\"z\"][:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(acts[\"TruthfulQA\"].dataset.all_labels)[acts[\"TruthfulQA\"].indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(acts[\"TruthfulQA\"].dataset.all_labels)[acts[\"TruthfulQA\"].indices_tests[\"z\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(acts[\"BoolQ\"].dataset.sample(1000)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts[\"BoolQ\"].dataset.all_prompts == iti_acts[\"BoolQ\"].dataset.all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(acts[\"BoolQ\"].dataset.all_labels)[acts[\"BoolQ\"].dataset.sample(1000)[0]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_judge import get_iti_scores\n",
    "# Try GPT-Judge output, measure truthfulness and info before/after ITI\n",
    "\n",
    "truth_scores = []\n",
    "info_scores = []\n",
    "truth_scores_iti = []\n",
    "info_scores_iti = []\n",
    "\n",
    "for name in tqdm(datanames):\n",
    "    truth_score, info_score, truth_score_iti, info_score_iti, _, _ = get_iti_scores(model, datasets[name], alpha=1, topk=1200, existing_acts=acts[name])\n",
    "    truth_scores.append(truth_score)\n",
    "    info_scores.append(info_score)\n",
    "    truth_scores_iti.append(truth_score_iti)\n",
    "    info_scores_iti.append(info_score_iti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure truthfulness before/after ITI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors=['b', 'r']\n",
    "names=[\"default\", \"iti\"]\n",
    "probe_acc_dict = {}\n",
    "for idx, score_list in enumerate([truth_scores, truth_scores_iti]):\n",
    "    model_acc_diffs = []\n",
    "    probe_accs = []\n",
    "    for name_idx, name in enumerate(datanames):\n",
    "        model_acc_diffs.append(score_list[name_idx])\n",
    "        probe_accs.append(acts[name].probe_accs[\"z\"].mean())\n",
    "        probe_acc_dict[name] = round(acts[name].probe_accs[\"z\"].mean(), 3)\n",
    "\n",
    "    plt.scatter(probe_accs, model_acc_diffs, c=colors[idx], label=names[idx])\n",
    "\n",
    "plt.title(\"Truth Evaluation of Models on Datasets\")\n",
    "plt.xlabel(\"Probe Accuracy\")\n",
    "plt.ylabel(\"Model Truth Evaluation (GPT-Judge)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(probe_acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure truthfulness before/after ITI\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors=['b', 'r']\n",
    "names=[\"default\", \"iti\"]\n",
    "probe_acc_dict = {}\n",
    "for idx, score_list in enumerate([info_scores, info_scores_iti]):\n",
    "    model_acc_diffs = []\n",
    "    probe_accs = []\n",
    "    for name_idx, name in enumerate(datanames):\n",
    "        model_acc_diffs.append(score_list[name_idx])\n",
    "        probe_accs.append(acts[name].probe_accs[\"z\"].mean())\n",
    "        probe_acc_dict[name] = round(acts[name].probe_accs[\"z\"].mean(), 3)\n",
    "\n",
    "    plt.scatter(probe_accs, model_acc_diffs, c=colors[idx], label=names[idx])\n",
    "\n",
    "plt.title(\"Informative Evaluation of Models on Datasets\")\n",
    "plt.xlabel(\"Probe Accuracy\")\n",
    "plt.ylabel(\"Model Info Evaluation (GPT-Judge)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(probe_acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Test ITI generalization\n",
    "n_acts = 1000\n",
    "# First, plot the old scatters, default accs and iti on same data\n",
    "colors=['b', 'r']\n",
    "names=[\"default\", \"iti_on_same_data\"]\n",
    "for idx, act_list in enumerate([acts, iti_acts]):\n",
    "    model_acc_diffs = []\n",
    "    probe_accs = []\n",
    "    for name in datanames:\n",
    "        act_list[name].indices_trains = acts[name].indices_trains\n",
    "        act_list[name].indices_tests = acts[name].indices_tests\n",
    "\n",
    "        positive_sum, negative_sum = tot_logit_diff(act_list[name], use_probs=True)\n",
    "        model_acc_diffs.append(positive_sum.mean() - negative_sum.mean())\n",
    "\n",
    "        probe_accs.append(acts[name].probe_accs[\"z\"].mean())\n",
    "\n",
    "    plt.scatter(probe_accs, model_acc_diffs, c=colors[idx], label=names[idx])\n",
    "\n",
    "# next, plot scatter after doing ITI from one dataset, model acc from others\n",
    "colors=['g', 'y', 'pink', 'purple', 'black', 'cyan']\n",
    "names=[f\"iti on {name}\" for name in datanames]\n",
    "print(\"done with old\")\n",
    "\n",
    "# all_iti_acts = {}\n",
    "for idx, iti_name in enumerate(datanames):\n",
    "    iti_acts_temp = {}\n",
    "    # regenerate ITI \n",
    "    # cache_interventions = torch.zeros(size=(model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head))\n",
    "    \n",
    "    probe_accs = []\n",
    "    model_acc_diffs = []\n",
    "    patch_iti(model, acts[iti_name], topk=50, alpha=20, use_MMD=True, model_device=\"cuda\", train_only=True)\n",
    "    for data_name in datanames:\n",
    "        iti_acts_temp[data_name] = ModelActs(model, datasets[data_name], act_types = [\"z\", \"mlp_out\", \"logits\"])\n",
    "                                            #  act_types=[\"z\", \"mlp_out\", \"resid_post\", \"resid_pre\", \"logits\"])\n",
    "        model_acts: ModelActs = iti_acts_temp[data_name]\n",
    "        model_acts.gen_acts(N=n_acts, id=f\"iti_{iti_name}_data_{data_name}_gpt2xl_{n_acts}\", indices=acts[data_name].indices)\n",
    "        # model_acts.load_acts(id=f\"iti_{iti_name}_data_{data_name}_gpt2xl_{n_acts}\", load_probes=False)\n",
    "        # model_acts.train_probes(\"z\", max_iter=1000)\n",
    "        model_acts.indices_trains = acts[data_name].indices_trains\n",
    "        model_acts.indices_tests = acts[data_name].indices_tests\n",
    "        \n",
    "        positive_sum, negative_sum = tot_logit_diff(model_acts, use_probs=True)\n",
    "        model_acc_diffs.append(positive_sum.mean() - negative_sum.mean())\n",
    "        probe_accs.append(acts[data_name].probe_accs[\"z\"].mean())\n",
    "    \n",
    "    # all_iti_acts[iti_name] = iti_acts_temp\n",
    "    # with open(f'activations/iti_{iti_name}_all_modelacts.pickle', 'wb') as handle:\n",
    "    #     pickle.dump(iti_acts_temp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    plt.scatter(probe_accs, model_acc_diffs, c=colors[idx], label=names[idx])\n",
    "\n",
    "\n",
    "plt.xlabel(\"Probe Accuracy\")\n",
    "plt.ylabel(\"Model Accuracy Differential\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph of model accuracy differential vs probe accuracy\n",
    "\n",
    "\n",
    "for name in datanames:\n",
    "\n",
    "    probe_accs = []\n",
    "    positive_sum, negative_sum = tot_logit_diff(acts[name], use_probs=True)\n",
    "    model_acc_diffs = (positive_sum - negative_sum)\n",
    "    for i in tqdm(range(1000)):\n",
    "        point = einops.rearrange(acts[\"MS\"].stored_acts[\"z\"][i], \"n_l n_h d_p -> (n_l n_h) d_p\")\n",
    "        label = acts[\"MS\"].dataset.all_labels[acts[\"MS\"].indices[i]]\n",
    "        probe_acc = get_datapoint_probe_acc(acts[\"MS\"], point, label, \"z\")\n",
    "        probe_accs.append(sum(probe_acc)/len(probe_acc))\n",
    "        \n",
    "    plt.scatter(model_acc_diffs, probe_accs)\n",
    "\n",
    "    break\n",
    "plt.xlabel(\"Model Accuracy Differential\")\n",
    "plt.ylabel(\"Probe Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in datanames:\n",
    "    # acts[name] = ModelActs(model, datasets[name], act_types=[\"z\", \"mlp_out\", \"resid_post\", \"resid_pre\", \"result\", \"logits\"])\n",
    "    model_acts: ModelActs = acts[name]\n",
    "    model_acts.train_probes(\"resid_post\", max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_probe_accs(model_acts, points, labels, act_type):\n",
    "    \"\"\"\n",
    "    Get probe accuracy over multiple datapoints\n",
    "    points in shape (batch, num_probes, d_probe)\n",
    "    \"\"\"\n",
    "    # print(f\"{point.shape=}\")\n",
    "    all_probe_accs = []\n",
    "    for idx, probe in enumerate(model_acts.probes[act_type]):\n",
    "        probe_accs = []\n",
    "        y_pred = probe.predict_proba(points[:,idx].numpy())\n",
    "\n",
    "        for data_idx, label in enumerate(labels):\n",
    "            if label == 1.0:\n",
    "                # then 1st is good\n",
    "                probe_accs.append(y_pred[data_idx][1])\n",
    "            else:\n",
    "                probe_accs.append(y_pred[data_idx][0])\n",
    "        all_probe_accs.append(probe_accs)\n",
    "\n",
    "    return all_probe_accs\n",
    "\n",
    "\n",
    "# colors = {\"MS\": 'b', \"Elem\": 'g', \"MisCons\": 'r', \"Kinder\": 'purple', \"HS\": 'black', \"BoolQ\": 'cyan'}\n",
    "for name in tqdm(datanames):\n",
    "\n",
    "    positive_sum, negative_sum = tot_logit_diff(acts[name], use_probs=True)\n",
    "    model_acc_diffs = (positive_sum - negative_sum)\n",
    "\n",
    "    X_test = acts[\"MS\"].X_tests[\"z\"]# einops.rearrange(acts[\"MS\"].X_tests[\"z\"], \"b n_l n_h d_p -> b (n_l n_h) d_p\")\n",
    "    label = torch.tensor(acts[\"MS\"].dataset.all_labels)[acts[\"MS\"].indices_tests[\"z\"]]\n",
    "    # print(label.shape)\n",
    "    # print(X_test.shape)\n",
    "    probe_accs = torch.tensor(get_data_probe_accs(acts[name], X_test, label, \"z\"))\n",
    "    print(model_acc_diffs.shape)\n",
    "    print(probe_accs.shape)\n",
    "    # probe_accs.append(sum(probe_acc)/len(probe_acc))\n",
    "        \n",
    "    plt.scatter(model_acc_diffs, probe_accs.mean(dim=0), label=name, s=2)\n",
    "\n",
    "    # break\n",
    "plt.title(\"Testing Probes from each Datasource on MS Test Data\")\n",
    "plt.xlabel(\"Model Accuracy Differential\")\n",
    "plt.ylabel(\"Probe Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"MS\"\n",
    "colors = ['r', 'cyan']\n",
    "names = [\"Before ITI\", \"After ITI\"]\n",
    "\n",
    "for idx, act_list in enumerate([acts, iti_acts]):\n",
    "\n",
    "    positive_sum, negative_sum = tot_logit_diff(act_list[name], use_probs=True)\n",
    "    model_acc_diffs = (positive_sum - negative_sum)\n",
    "\n",
    "    X_test = acts[\"MS\"].X_tests[\"z\"]# einops.rearrange(acts[\"MS\"].X_tests[\"z\"], \"b n_l n_h d_p -> b (n_l n_h) d_p\")\n",
    "    label = torch.tensor(acts[\"MS\"].dataset.all_labels)[acts[\"MS\"].indices_tests[\"z\"]]\n",
    "    probe_accs = torch.tensor(get_data_probe_accs(acts[name], X_test, label, \"z\"))\n",
    "    print(model_acc_diffs.shape)\n",
    "    print(probe_accs.shape)\n",
    "    # probe_accs.append(sum(probe_acc)/len(probe_acc))\n",
    "        \n",
    "    plt.scatter(model_acc_diffs, probe_accs.mean(dim=0), color=colors[idx], label=names[idx], alpha=.5, s=2)\n",
    "\n",
    "    # break\n",
    "plt.title(f\"Testing Probes before ITI and after ITI on {name} Test Data\")\n",
    "plt.xlabel(\"Model Accuracy Differential\")\n",
    "plt.ylabel(\"Probe Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"MS\": 'b', \"Elem\": 'g', \"MisCons\": 'r', \"Kinder\": 'purple', \"HS\": 'black', \"BoolQ\": 'yellow'}\n",
    "for name in tqdm(datanames):\n",
    "\n",
    "    positive_sum, negative_sum = tot_logit_diff(acts[name], use_probs=True)\n",
    "    model_acc_diffs = (positive_sum - negative_sum)\n",
    "\n",
    "    X_test = acts[\"MS\"].stored_acts[\"resid_post\"]\n",
    "    label = torch.tensor(acts[\"MS\"].dataset.all_labels)[acts[\"MS\"].indices]\n",
    "    # print(label.shape)\n",
    "    # print(X_test.shape)\n",
    "    probe_accs = torch.tensor(get_data_probe_accs(acts[\"MS\"], X_test, label, \"resid_post\"))\n",
    "    # print(probe_accs.shape)\n",
    "    # probe_accs.append(sum(probe_acc)/len(probe_acc))\n",
    "        \n",
    "    plt.scatter(model_acc_diffs, probe_accs.mean(dim=0), color=colors[name], label=name, alpha=.5, s=2)\n",
    "\n",
    "    # break\n",
    "plt.xlabel(\"Model Accuracy Differential\")\n",
    "plt.ylabel(\"Probe Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_judge import get_iti_scores\n",
    "plots = []\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "for name in datanames:\n",
    "    get_iti_scores(model, datasets[name], alpha=20, topk=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gpt_judge import get_iti_scores\n",
    "plots = []\n",
    "\n",
    "for name in datanames:\n",
    "    get_iti_scores(model, datasets[name], alpha=1, topk=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from utils.gpt_judge import check_iti_generalization\n",
    "plots = []\n",
    "\n",
    "for name in datanames:\n",
    "    model_acts: ModelActs = acts[name]\n",
    "    for other_name in datanames:\n",
    "        print(f\"Checking generation on {name}, ITI on {other_name}\")\n",
    "        results = check_iti_generalization(model, datasets[name], datasets[other_name], 50, 1000, alpha=1, topk=1200, existing_gen_acts=model_acts)\n",
    "        print(f\"Truth score before ITI: {results[0]}, Truth score after ITI: {results[2]}\")\n",
    "        print(f\"Info score before ITI: {results[1]}, Info score after ITI: {results[3]}\")\n",
    "        print()\n",
    "\n",
    "        break\n",
    "    break\n",
    "\n",
    "        # transfer_accs = model_acts.get_transfer_acc(acts[other_name])\n",
    "        # plots.append(plot_probe_accuracies(model_acts, sorted=False, title=f\"{name} probes on {other_name} data\", other_head_accs=transfer_accs).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from utils.gpt_judge import check_iti_generalization\n",
    "plots = []\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "for name in datanames[1:]:\n",
    "    model_acts: ModelActs = acts[name]\n",
    "    for other_name in datanames:\n",
    "        print(f\"Checking generation on {name}, ITI on {other_name}\")\n",
    "        results = check_iti_generalization(model, datasets[name], datasets[other_name], 50, 1000, alpha=10, existing_gen_acts=acts[name])\n",
    "        print(f\"Truth score before ITI: {results[0]}, Truth score after ITI: {results[2]}\")\n",
    "        print(f\"Info score before ITI: {results[1]}, Info score after ITI: {results[3]}\")\n",
    "        print()\n",
    "\n",
    "        # transfer_accs = model_acts.get_transfer_acc(acts[other_name])\n",
    "        # plots.append(plot_probe_accuracies(model_acts, sorted=False, title=f\"{name} probes on {other_name} data\", other_head_accs=transfer_accs).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig_combined = make_subplots(rows=3, cols=3)\n",
    "\n",
    "for i, fig in enumerate(plots):\n",
    "    row = i // 3 + 1  # calculate the row index\n",
    "    col = i % 3 + 1   # calculate the column index\n",
    "\n",
    "    # Extract data from the individual figures and add it to the subplots\n",
    "    for trace in fig.data:\n",
    "        fig_combined.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=trace.z,\n",
    "                x0=trace.x[0],\n",
    "                dx=trace.x[1] - trace.x[0],\n",
    "                y0=trace.y[0],\n",
    "                dy=trace.y[1] - trace.y[0],\n",
    "                zmin=trace.zmin,\n",
    "                zmax=trace.zmax,\n",
    "                coloraxis=trace.coloraxis,\n",
    "                showscale=False,\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "# Add a colorbar that's common to all subplots\n",
    "fig.update_layout(coloraxis=dict(colorscale='viridis', colorbar=dict(tickfont=dict(size=10))))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
